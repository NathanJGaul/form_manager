{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# JCC2 Comprehensive Section Visualizations\n\nThis notebook provides comprehensive visualizations for ALL sections of the JCC2 User Questionnaire.\n\n## Sections Covered:\n1. **System Fields** - Status, progress, timestamps\n2. **User Information** - Demographics and participation\n3. **Role and Echelon** - Positions and responsibilities\n4. **Operational JCC2 Experience** - Application experience levels\n5. **JCC2 Application Usage** - Frequency and training\n6. **MOP Sections** - Measures of Performance (1.1.1 through 2.4.1)\n7. **MOS Sections** - Measures of Suitability (1.1.2 through 3.2.2)\n8. **Reporting and Data Export** - System capabilities\n9. **Overall System Usability** - SUS scores and feedback\n10. **Overall System Suitability Evaluation** - Final assessments\n\nEach section includes tailored visualizations based on the data types and patterns found, while maintaining context of the overall dataset."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import JCC2 processor\n",
    "from jcc2_data_processor import create_processor, DataFormat\n",
    "\n",
    "# Set up visualization style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"Set2\")\n",
    "\n",
    "# Configure display options\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Color palette for consistent styling\n",
    "COLORS = {\n",
    "    'primary': '#2E86AB',\n",
    "    'secondary': '#A23B72',\n",
    "    'tertiary': '#F18F01',\n",
    "    'quaternary': '#C73E1D',\n",
    "    'success': '#52B788',\n",
    "    'warning': '#F77F00',\n",
    "    'info': '#5C946E'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "csv_file = \"mock_20_jcc2_user_questionnaire.csv\"\n",
    "processor = create_processor(csv_file)\n",
    "df = processor.load_data()\n",
    "\n",
    "print(f\"Loaded {len(df)} responses\")\n",
    "print(f\"Data format: {processor.format_type.value}\")\n",
    "print(f\"\\nSections to analyze:\")\n",
    "sections_to_analyze = ['user_information', 'role_and_echelon', 'operational_jcc2_experience', 'mop_1_1_1']\n",
    "for section in sections_to_analyze:\n",
    "    if section in processor.sections:\n",
    "        print(f\"  - {section}: {len(processor.sections[section])} fields\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. User Information Section Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze user_information section\n",
    "user_info_summary = processor.get_section_summary('user_information')\n",
    "print(\"User Information Fields:\")\n",
    "for field, data in user_info_summary['field_summaries'].items():\n",
    "    print(f\"  - {field}: {data['field_type']} (completion: {data['completion_rate']:.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User Information Visualizations\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "\n",
    "# 1. Event participation distribution\n",
    "ax1 = plt.subplot(2, 3, 1)\n",
    "event_data = df['user_information.event'].value_counts()\n",
    "event_data.plot(kind='bar', ax=ax1, color=COLORS['primary'])\n",
    "ax1.set_title('Distribution of Events', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Event Name')\n",
    "ax1.set_ylabel('Number of Participants')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 2. Participation timeline\n",
    "ax2 = plt.subplot(2, 3, 2)\n",
    "df['user_information.date'] = pd.to_datetime(df['user_information.date'])\n",
    "date_counts = df['user_information.date'].value_counts().sort_index()\n",
    "date_counts.plot(kind='line', ax=ax2, color=COLORS['secondary'], marker='o')\n",
    "ax2.set_title('Participation Timeline', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Date')\n",
    "ax2.set_ylabel('Number of Responses')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 3. Unit distribution (top 10)\n",
    "ax3 = plt.subplot(2, 3, 3)\n",
    "unit_data = df['user_information.unit'].value_counts().head(10)\n",
    "unit_data.plot(kind='barh', ax=ax3, color=COLORS['tertiary'])\n",
    "ax3.set_title('Top 10 Units by Participation', fontsize=14, fontweight='bold')\n",
    "ax3.set_xlabel('Number of Participants')\n",
    "ax3.set_ylabel('Unit')\n",
    "\n",
    "# 4. Rank distribution word cloud style (simplified as bar chart)\n",
    "ax4 = plt.subplot(2, 3, 4)\n",
    "rank_data = df['user_information.rank_name'].value_counts().head(15)\n",
    "rank_data.plot(kind='pie', ax=ax4, autopct='%1.1f%%', startangle=90)\n",
    "ax4.set_title('Rank Distribution', fontsize=14, fontweight='bold')\n",
    "ax4.set_ylabel('')\n",
    "\n",
    "# 5. Contact information completion rates\n",
    "ax5 = plt.subplot(2, 3, 5)\n",
    "contact_fields = ['user_information.email', 'user_information.phone']\n",
    "completion_rates = [df[field].notna().mean() for field in contact_fields]\n",
    "ax5.bar(['Email', 'Phone'], completion_rates, color=[COLORS['success'], COLORS['info']])\n",
    "ax5.set_title('Contact Information Completion Rates', fontsize=14, fontweight='bold')\n",
    "ax5.set_ylabel('Completion Rate')\n",
    "ax5.set_ylim(0, 1)\n",
    "for i, v in enumerate(completion_rates):\n",
    "    ax5.text(i, v + 0.02, f'{v:.1%}', ha='center', fontweight='bold')\n",
    "\n",
    "# 6. Data quality summary\n",
    "ax6 = plt.subplot(2, 3, 6)\n",
    "quality_data = {\n",
    "    'Complete Records': (df[['user_information.event', 'user_information.date', \n",
    "                            'user_information.rank_name', 'user_information.unit']].notna().all(axis=1)).sum(),\n",
    "    'Partial Records': len(df) - (df[['user_information.event', 'user_information.date', \n",
    "                                      'user_information.rank_name', 'user_information.unit']].notna().all(axis=1)).sum()\n",
    "}\n",
    "ax6.pie(quality_data.values(), labels=quality_data.keys(), autopct='%1.1f%%', \n",
    "        colors=[COLORS['success'], COLORS['warning']], startangle=90)\n",
    "ax6.set_title('Data Completeness', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.suptitle('User Information Section Analysis', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Role and Echelon Section Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze role_and_echelon section\n",
    "role_summary = processor.get_section_summary('role_and_echelon')\n",
    "print(\"Role and Echelon Fields:\")\n",
    "for field, data in role_summary['field_summaries'].items():\n",
    "    print(f\"  - {field}: {data['field_type']} (completion: {data['completion_rate']:.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Role and Echelon Visualizations\n",
    "fig = plt.figure(figsize=(20, 15))\n",
    "\n",
    "# 1. Current role status distribution\n",
    "ax1 = plt.subplot(3, 3, 1)\n",
    "role_status = df['role_and_echelon.current_role_status'].value_counts()\n",
    "colors = [COLORS['primary'], COLORS['secondary'], COLORS['tertiary'], COLORS['quaternary']][:len(role_status)]\n",
    "role_status.plot(kind='pie', ax=ax1, autopct='%1.1f%%', colors=colors, startangle=45)\n",
    "ax1.set_title('Current Role Status Distribution', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylabel('')\n",
    "\n",
    "# 2. Cyber operator distribution\n",
    "ax2 = plt.subplot(3, 3, 2)\n",
    "cyber_op = df['role_and_echelon.is_cyber_operator'].value_counts()\n",
    "cyber_op.plot(kind='bar', ax=ax2, color=[COLORS['success'], COLORS['warning']])\n",
    "ax2.set_title('Cyber Operator Distribution', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Is Cyber Operator')\n",
    "ax2.set_ylabel('Count')\n",
    "ax2.tick_params(axis='x', rotation=0)\n",
    "for i, v in enumerate(cyber_op.values):\n",
    "    ax2.text(i, v + 0.5, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "# 3. Echelon distribution (for cyber operators)\n",
    "ax3 = plt.subplot(3, 3, 3)\n",
    "cyber_ops_df = df[df['role_and_echelon.is_cyber_operator'] == 'Yes']\n",
    "if not cyber_ops_df.empty and 'role_and_echelon.echelon' in cyber_ops_df.columns:\n",
    "    # Parse echelon data (assuming it's a multi-select field)\n",
    "    echelon_counts = {}\n",
    "    for echelons in cyber_ops_df['role_and_echelon.echelon'].dropna():\n",
    "        if isinstance(echelons, list):\n",
    "            for echelon in echelons:\n",
    "                echelon_counts[echelon] = echelon_counts.get(echelon, 0) + 1\n",
    "        else:\n",
    "            # Handle if it's stored as string\n",
    "            for echelon in str(echelons).split('; '):\n",
    "                if echelon:\n",
    "                    echelon_counts[echelon] = echelon_counts.get(echelon, 0) + 1\n",
    "    \n",
    "    if echelon_counts:\n",
    "        echelon_df = pd.Series(echelon_counts).sort_values(ascending=True)\n",
    "        echelon_df.plot(kind='barh', ax=ax3, color=COLORS['info'])\n",
    "        ax3.set_title('Echelon Levels (Cyber Operators)', fontsize=14, fontweight='bold')\n",
    "        ax3.set_xlabel('Count')\n",
    "else:\n",
    "    ax3.text(0.5, 0.5, 'No cyber operator echelon data', ha='center', va='center', transform=ax3.transAxes)\n",
    "    ax3.set_title('Echelon Levels (Cyber Operators)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 4. Duties distribution (multi-select analysis)\n",
    "ax4 = plt.subplot(3, 3, 4)\n",
    "duties_counts = {}\n",
    "for duties in df['role_and_echelon.duties'].dropna():\n",
    "    if isinstance(duties, list):\n",
    "        for duty in duties:\n",
    "            duties_counts[duty] = duties_counts.get(duty, 0) + 1\n",
    "    else:\n",
    "        # Handle if it's stored as string\n",
    "        for duty in str(duties).split('; '):\n",
    "            if duty:\n",
    "                duties_counts[duty] = duties_counts.get(duty, 0) + 1\n",
    "\n",
    "if duties_counts:\n",
    "    duties_df = pd.Series(duties_counts).sort_values(ascending=False)\n",
    "    duties_df.plot(kind='bar', ax=ax4, color=COLORS['primary'])\n",
    "    ax4.set_title('Primary Duties Distribution', fontsize=14, fontweight='bold')\n",
    "    ax4.set_xlabel('Duty Type')\n",
    "    ax4.set_ylabel('Count')\n",
    "    ax4.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 5. Cyber division/team distribution\n",
    "ax5 = plt.subplot(3, 3, 5)\n",
    "if 'role_and_echelon.cyber_ops_division_team' in df.columns:\n",
    "    cyber_teams = df['role_and_echelon.cyber_ops_division_team'].dropna().value_counts().head(10)\n",
    "    if not cyber_teams.empty:\n",
    "        cyber_teams.plot(kind='barh', ax=ax5, color=COLORS['secondary'])\n",
    "        ax5.set_title('Top 10 Cyber Ops Divisions/Teams', fontsize=14, fontweight='bold')\n",
    "        ax5.set_xlabel('Count')\n",
    "    else:\n",
    "        ax5.text(0.5, 0.5, 'No cyber team data available', ha='center', va='center', transform=ax5.transAxes)\n",
    "\n",
    "# 6. Role status by cyber operator status\n",
    "ax6 = plt.subplot(3, 3, 6)\n",
    "role_cyber_cross = pd.crosstab(df['role_and_echelon.current_role_status'], \n",
    "                               df['role_and_echelon.is_cyber_operator'])\n",
    "role_cyber_cross.plot(kind='bar', ax=ax6, color=[COLORS['success'], COLORS['warning']])\n",
    "ax6.set_title('Role Status by Cyber Operator Status', fontsize=14, fontweight='bold')\n",
    "ax6.set_xlabel('Current Role Status')\n",
    "ax6.set_ylabel('Count')\n",
    "ax6.legend(title='Is Cyber Operator')\n",
    "ax6.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 7. Duty combinations heatmap\n",
    "ax7 = plt.subplot(3, 3, 7)\n",
    "# Create a co-occurrence matrix for duties\n",
    "duty_combinations = []\n",
    "for duties in df['role_and_echelon.duties'].dropna():\n",
    "    if isinstance(duties, list):\n",
    "        duty_combinations.append(duties)\n",
    "    else:\n",
    "        duty_combinations.append(str(duties).split('; '))\n",
    "\n",
    "# Count co-occurrences\n",
    "unique_duties = list(duties_counts.keys()) if duties_counts else []\n",
    "co_matrix = pd.DataFrame(0, index=unique_duties[:6], columns=unique_duties[:6])  # Top 6 for readability\n",
    "\n",
    "for combo in duty_combinations:\n",
    "    for i, duty1 in enumerate(combo):\n",
    "        for duty2 in combo[i:]:\n",
    "            if duty1 in co_matrix.index and duty2 in co_matrix.columns:\n",
    "                co_matrix.loc[duty1, duty2] += 1\n",
    "                if duty1 != duty2:\n",
    "                    co_matrix.loc[duty2, duty1] += 1\n",
    "\n",
    "if not co_matrix.empty:\n",
    "    sns.heatmap(co_matrix, annot=True, fmt='d', cmap='YlOrRd', ax=ax7, cbar_kws={'label': 'Co-occurrence Count'})\n",
    "    ax7.set_title('Duty Combinations Heatmap', fontsize=14, fontweight='bold')\n",
    "    ax7.tick_params(axis='x', rotation=45)\n",
    "    ax7.tick_params(axis='y', rotation=0)\n",
    "\n",
    "# 8. Other duties word frequency (simplified)\n",
    "ax8 = plt.subplot(3, 3, 8)\n",
    "other_duties = df['role_and_echelon.other_duties'].dropna()\n",
    "if not other_duties.empty:\n",
    "    # Simple word frequency analysis\n",
    "    all_words = ' '.join(other_duties.astype(str)).lower().split()\n",
    "    word_freq = pd.Series(all_words).value_counts().head(20)\n",
    "    word_freq.plot(kind='barh', ax=ax8, color=COLORS['info'])\n",
    "    ax8.set_title('Top 20 Words in \"Other Duties\"', fontsize=14, fontweight='bold')\n",
    "    ax8.set_xlabel('Frequency')\n",
    "else:\n",
    "    ax8.text(0.5, 0.5, 'No \"other duties\" data', ha='center', va='center', transform=ax8.transAxes)\n",
    "\n",
    "# 9. Completeness by field\n",
    "ax9 = plt.subplot(3, 3, 9)\n",
    "role_fields = [col for col in df.columns if col.startswith('role_and_echelon.')]\n",
    "completeness = [(col.split('.')[-1], df[col].notna().mean()) for col in role_fields]\n",
    "completeness_df = pd.DataFrame(completeness, columns=['Field', 'Completion Rate']).sort_values('Completion Rate')\n",
    "completeness_df.plot(x='Field', y='Completion Rate', kind='barh', ax=ax9, color=COLORS['primary'], legend=False)\n",
    "ax9.set_title('Field Completion Rates', fontsize=14, fontweight='bold')\n",
    "ax9.set_xlabel('Completion Rate')\n",
    "ax9.set_xlim(0, 1)\n",
    "for i, (field, rate) in enumerate(completeness_df.values):\n",
    "    ax9.text(rate + 0.02, i, f'{rate:.1%}', va='center', fontsize=9)\n",
    "\n",
    "plt.suptitle('Role and Echelon Section Analysis', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Operational JCC2 Experience Section Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze operational_jcc2_experience section\n",
    "ops_summary = processor.get_section_summary('operational_jcc2_experience')\n",
    "print(\"Operational JCC2 Experience Fields:\")\n",
    "experience_fields = {}\n",
    "for field, data in ops_summary['field_summaries'].items():\n",
    "    field_name = field.split('.')[-1]\n",
    "    if field_name.startswith('exp_'):\n",
    "        experience_fields[field_name] = data\n",
    "        print(f\"  - {field_name}: {data['field_type']} (completion: {data['completion_rate']:.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operational JCC2 Experience Visualizations\n",
    "fig = plt.figure(figsize=(24, 20))\n",
    "\n",
    "# Extract experience levels for all applications\n",
    "app_experience = {}\n",
    "experience_mapping = {\n",
    "    'exp_cyberoperations': 'Cyber Operations',\n",
    "    'exp_yourcurrentrole': 'Current Role',\n",
    "    'exp_jcc2experience': 'JCC2 Experience',\n",
    "    'exp_app_a2it': 'A2IT',\n",
    "    'exp_app_cad': 'CAD',\n",
    "    'exp_app_codex': 'Codex',\n",
    "    'exp_app_crucible': 'Crucible',\n",
    "    'exp_app_cyber9line': 'Cyber 9-Line',\n",
    "    'exp_app_dispatch': 'Dispatch',\n",
    "    'exp_app_jcc2cyberops': 'JCC2 Cyber-Ops',\n",
    "    'exp_app_jcc2readiness': 'JCC2 Readiness',\n",
    "    'exp_app_madss': 'MADSS',\n",
    "    'exp_app_rally': 'Rally',\n",
    "    'exp_app_redmap': 'REDMAP',\n",
    "    'exp_app_sigact': 'SigAct',\n",
    "    'exp_app_threathub': 'Threat Hub',\n",
    "    'exp_app_triage': 'Triage',\n",
    "    'exp_app_unity': 'Unity'\n",
    "}\n",
    "\n",
    "# 1. Overall experience distribution (first 3 fields)\n",
    "ax1 = plt.subplot(4, 3, 1)\n",
    "overall_exp_fields = ['exp_cyberoperations', 'exp_yourcurrentrole', 'exp_jcc2experience']\n",
    "for i, field in enumerate(overall_exp_fields):\n",
    "    if f'operational_jcc2_experience.{field}' in df.columns:\n",
    "        exp_data = df[f'operational_jcc2_experience.{field}'].value_counts()\n",
    "        exp_data.plot(kind='bar', ax=ax1, alpha=0.7, label=experience_mapping.get(field, field))\n",
    "ax1.set_title('Overall Experience Levels', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Experience Level')\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.legend()\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 2. Application experience heatmap\n",
    "ax2 = plt.subplot(4, 3, (2, 6))  # Span multiple cells\n",
    "app_exp_data = []\n",
    "exp_order = ['< 1 Year', '1-3 Years', '3-5 Years', '> 5 Years', 'NA']\n",
    "for field, label in experience_mapping.items():\n",
    "    if field.startswith('exp_app_') and f'operational_jcc2_experience.{field}' in df.columns:\n",
    "        counts = df[f'operational_jcc2_experience.{field}'].value_counts()\n",
    "        row_data = [counts.get(exp, 0) for exp in exp_order]\n",
    "        app_exp_data.append(row_data)\n",
    "\n",
    "if app_exp_data:\n",
    "    app_labels = [v for k, v in experience_mapping.items() if k.startswith('exp_app_')]\n",
    "    exp_matrix = pd.DataFrame(app_exp_data, index=app_labels[:len(app_exp_data)], columns=exp_order)\n",
    "    sns.heatmap(exp_matrix, annot=True, fmt='d', cmap='YlOrRd', ax=ax2, cbar_kws={'label': 'Number of Users'})\n",
    "    ax2.set_title('Application Experience Heatmap', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('Experience Level')\n",
    "    ax2.set_ylabel('Application')\n",
    "\n",
    "# 3. Experience distribution by application (stacked bar)\n",
    "ax3 = plt.subplot(4, 3, (7, 9))  # Span multiple cells\n",
    "if app_exp_data:\n",
    "    exp_matrix_pct = exp_matrix.div(exp_matrix.sum(axis=1), axis=0) * 100\n",
    "    exp_matrix_pct.plot(kind='barh', stacked=True, ax=ax3, colormap='viridis')\n",
    "    ax3.set_title('Experience Distribution by Application (%)', fontsize=14, fontweight='bold')\n",
    "    ax3.set_xlabel('Percentage')\n",
    "    ax3.set_ylabel('Application')\n",
    "    ax3.legend(title='Experience', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# 4. Applications with most experienced users\n",
    "ax4 = plt.subplot(4, 3, 10)\n",
    "experienced_users = {}\n",
    "for field, label in experience_mapping.items():\n",
    "    if field.startswith('exp_app_') and f'operational_jcc2_experience.{field}' in df.columns:\n",
    "        exp_counts = df[f'operational_jcc2_experience.{field}'].value_counts()\n",
    "        experienced = exp_counts.get('> 5 Years', 0) + exp_counts.get('3-5 Years', 0)\n",
    "        experienced_users[label] = experienced\n",
    "\n",
    "if experienced_users:\n",
    "    exp_series = pd.Series(experienced_users).sort_values(ascending=False).head(10)\n",
    "    exp_series.plot(kind='bar', ax=ax4, color=COLORS['success'])\n",
    "    ax4.set_title('Applications with Most Experienced Users (3+ Years)', fontsize=14, fontweight='bold')\n",
    "    ax4.set_xlabel('Application')\n",
    "    ax4.set_ylabel('Number of Experienced Users')\n",
    "    ax4.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 5. New user distribution (< 1 Year)\n",
    "ax5 = plt.subplot(4, 3, 11)\n",
    "new_users = {}\n",
    "for field, label in experience_mapping.items():\n",
    "    if field.startswith('exp_app_') and f'operational_jcc2_experience.{field}' in df.columns:\n",
    "        exp_counts = df[f'operational_jcc2_experience.{field}'].value_counts()\n",
    "        new = exp_counts.get('< 1 Year', 0)\n",
    "        new_users[label] = new\n",
    "\n",
    "if new_users:\n",
    "    new_series = pd.Series(new_users).sort_values(ascending=False).head(10)\n",
    "    new_series.plot(kind='bar', ax=ax5, color=COLORS['info'])\n",
    "    ax5.set_title('Applications with Most New Users (< 1 Year)', fontsize=14, fontweight='bold')\n",
    "    ax5.set_xlabel('Application')\n",
    "    ax5.set_ylabel('Number of New Users')\n",
    "    ax5.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 6. Application adoption rate (users with any experience vs NA)\n",
    "ax6 = plt.subplot(4, 3, 12)\n",
    "adoption_rates = {}\n",
    "for field, label in experience_mapping.items():\n",
    "    if field.startswith('exp_app_') and f'operational_jcc2_experience.{field}' in df.columns:\n",
    "        exp_counts = df[f'operational_jcc2_experience.{field}'].value_counts()\n",
    "        total_responses = exp_counts.sum()\n",
    "        na_count = exp_counts.get('NA', 0)\n",
    "        if total_responses > 0:\n",
    "            adoption_rate = (total_responses - na_count) / total_responses * 100\n",
    "            adoption_rates[label] = adoption_rate\n",
    "\n",
    "if adoption_rates:\n",
    "    adoption_series = pd.Series(adoption_rates).sort_values(ascending=True)\n",
    "    adoption_series.plot(kind='barh', ax=ax6, color=COLORS['primary'])\n",
    "    ax6.set_title('Application Adoption Rates', fontsize=14, fontweight='bold')\n",
    "    ax6.set_xlabel('Adoption Rate (%)')\n",
    "    ax6.set_ylabel('Application')\n",
    "    ax6.set_xlim(0, 100)\n",
    "    for i, (app, rate) in enumerate(adoption_series.items()):\n",
    "        ax6.text(rate + 1, i, f'{rate:.1f}%', va='center', fontsize=9)\n",
    "\n",
    "plt.suptitle('Operational JCC2 Experience Analysis', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional analysis: Experience correlation matrix\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "# Create numeric mapping for experience levels\n",
    "exp_numeric_map = {\n",
    "    '< 1 Year': 1,\n",
    "    '1-3 Years': 2,\n",
    "    '3-5 Years': 3,\n",
    "    '> 5 Years': 4,\n",
    "    'NA': 0\n",
    "}\n",
    "\n",
    "# Convert experience columns to numeric\n",
    "exp_columns = []\n",
    "exp_labels = []\n",
    "for field, label in experience_mapping.items():\n",
    "    if field.startswith('exp_app_') and f'operational_jcc2_experience.{field}' in df.columns:\n",
    "        col_name = f'operational_jcc2_experience.{field}'\n",
    "        df[f'{col_name}_numeric'] = df[col_name].map(exp_numeric_map).fillna(0)\n",
    "        exp_columns.append(f'{col_name}_numeric')\n",
    "        exp_labels.append(label)\n",
    "\n",
    "if exp_columns:\n",
    "    # Calculate correlation matrix\n",
    "    corr_matrix = df[exp_columns].corr()\n",
    "    \n",
    "    # Create mask for upper triangle\n",
    "    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "    \n",
    "    # Plot heatmap\n",
    "    sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "                center=0, square=True, linewidths=1, cbar_kws={\"shrink\": .8},\n",
    "                xticklabels=exp_labels, yticklabels=exp_labels, ax=ax)\n",
    "    ax.set_title('Application Experience Correlation Matrix', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Clean up numeric columns\n",
    "    df.drop(columns=exp_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. MOP 1.1.1 Intelligence Data Section Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze mop_1_1_1 section\n",
    "mop_summary = processor.get_section_summary('mop_1_1_1')\n",
    "print(\"MOP 1.1.1 Intelligence Data Fields:\")\n",
    "intel_fields = {}\n",
    "for field, data in mop_summary['field_summaries'].items():\n",
    "    field_name = field.split('.')[-1]\n",
    "    intel_fields[field_name] = data\n",
    "    print(f\"  - {field_name}: {data['field_type']} (completion: {data['completion_rate']:.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOP 1.1.1 Intelligence Data Visualizations\n",
    "fig = plt.figure(figsize=(24, 20))\n",
    "\n",
    "# Extract application names from field names\n",
    "intel_apps = set()\n",
    "for field in mop_summary['field_summaries'].keys():\n",
    "    parts = field.split('_')\n",
    "    if len(parts) > 3:\n",
    "        app_name = '_'.join(parts[3:]) if parts[2] in ['provided', 'completion'] else parts[-1]\n",
    "        intel_apps.add(app_name)\n",
    "\n",
    "intel_apps = sorted(list(intel_apps))\n",
    "\n",
    "# 1. Intelligence data provision by application\n",
    "ax1 = plt.subplot(4, 3, 1)\n",
    "provided_data = {}\n",
    "for app in intel_apps:\n",
    "    field_name = f'mop_1_1_1.intelligence_data_provided_{app}'\n",
    "    if field_name in df.columns:\n",
    "        counts = df[field_name].value_counts()\n",
    "        provided_data[app] = counts\n",
    "\n",
    "if provided_data:\n",
    "    # Calculate effectiveness scores\n",
    "    effectiveness_map = {\n",
    "        'Completely Ineffective': 1, 'Moderately Ineffective': 2, 'Slightly Ineffective': 3,\n",
    "        'Slightly Effective': 4, 'Moderately Effective': 5, 'Completely Effective': 6,\n",
    "        'Not Applicable': 0\n",
    "    }\n",
    "    \n",
    "    avg_scores = {}\n",
    "    for app, counts in provided_data.items():\n",
    "        total_score = sum(effectiveness_map.get(rating, 0) * count for rating, count in counts.items())\n",
    "        total_responses = sum(count for rating, count in counts.items() if rating != 'Not Applicable')\n",
    "        if total_responses > 0:\n",
    "            avg_scores[app.upper()] = total_score / total_responses\n",
    "    \n",
    "    if avg_scores:\n",
    "        scores_series = pd.Series(avg_scores).sort_values(ascending=True)\n",
    "        scores_series.plot(kind='barh', ax=ax1, color=COLORS['primary'])\n",
    "        ax1.set_title('Average Intelligence Data Provision Effectiveness', fontsize=14, fontweight='bold')\n",
    "        ax1.set_xlabel('Average Effectiveness Score (1-6)')\n",
    "        ax1.set_xlim(0, 6)\n",
    "        for i, (app, score) in enumerate(scores_series.items()):\n",
    "            ax1.text(score + 0.1, i, f'{score:.2f}', va='center', fontsize=9)\n",
    "\n",
    "# 2. Role completion effectiveness by application\n",
    "ax2 = plt.subplot(4, 3, 2)\n",
    "completion_data = {}\n",
    "for app in intel_apps:\n",
    "    field_name = f'mop_1_1_1.intelligence_data_completion_of_role_{app}'\n",
    "    if field_name in df.columns:\n",
    "        counts = df[field_name].value_counts()\n",
    "        completion_data[app] = counts\n",
    "\n",
    "if completion_data:\n",
    "    avg_completion_scores = {}\n",
    "    for app, counts in completion_data.items():\n",
    "        total_score = sum(effectiveness_map.get(rating, 0) * count for rating, count in counts.items())\n",
    "        total_responses = sum(count for rating, count in counts.items() if rating != 'Not Applicable')\n",
    "        if total_responses > 0:\n",
    "            avg_completion_scores[app.upper()] = total_score / total_responses\n",
    "    \n",
    "    if avg_completion_scores:\n",
    "        comp_series = pd.Series(avg_completion_scores).sort_values(ascending=True)\n",
    "        comp_series.plot(kind='barh', ax=ax2, color=COLORS['secondary'])\n",
    "        ax2.set_title('Average Role Completion Support Effectiveness', fontsize=14, fontweight='bold')\n",
    "        ax2.set_xlabel('Average Effectiveness Score (1-6)')\n",
    "        ax2.set_xlim(0, 6)\n",
    "        for i, (app, score) in enumerate(comp_series.items()):\n",
    "            ax2.text(score + 0.1, i, f'{score:.2f}', va='center', fontsize=9)\n",
    "\n",
    "# 3. Overall intelligence effectiveness\n",
    "ax3 = plt.subplot(4, 3, 3)\n",
    "if 'mop_1_1_1.intelligence_data_overall_effectiveness' in df.columns:\n",
    "    overall_counts = df['mop_1_1_1.intelligence_data_overall_effectiveness'].value_counts()\n",
    "    colors_map = {\n",
    "        'Completely Effective': COLORS['success'],\n",
    "        'Moderately Effective': COLORS['info'],\n",
    "        'Slightly Effective': COLORS['primary'],\n",
    "        'Slightly Ineffective': COLORS['tertiary'],\n",
    "        'Moderately Ineffective': COLORS['warning'],\n",
    "        'Completely Ineffective': COLORS['quaternary'],\n",
    "        'Not Applicable': 'gray'\n",
    "    }\n",
    "    colors = [colors_map.get(rating, 'gray') for rating in overall_counts.index]\n",
    "    overall_counts.plot(kind='pie', ax=ax3, autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "    ax3.set_title('Overall Intelligence Data Effectiveness', fontsize=14, fontweight='bold')\n",
    "    ax3.set_ylabel('')\n",
    "\n",
    "# 4. Effectiveness comparison heatmap\n",
    "ax4 = plt.subplot(4, 3, (4, 6))  # Span multiple cells\n",
    "if provided_data and completion_data:\n",
    "    # Create comparison matrix\n",
    "    comparison_data = []\n",
    "    app_labels = []\n",
    "    \n",
    "    for app in intel_apps:\n",
    "        if app in provided_data and app in completion_data:\n",
    "            app_labels.append(app.upper())\n",
    "            row = []\n",
    "            \n",
    "            # Data provision scores\n",
    "            for rating in ['Completely Ineffective', 'Moderately Ineffective', 'Slightly Ineffective',\n",
    "                          'Slightly Effective', 'Moderately Effective', 'Completely Effective']:\n",
    "                row.append(provided_data[app].get(rating, 0))\n",
    "            \n",
    "            comparison_data.append(row)\n",
    "    \n",
    "    if comparison_data:\n",
    "        comp_df = pd.DataFrame(comparison_data, index=app_labels, \n",
    "                              columns=['Completely\\nIneffective', 'Moderately\\nIneffective', 'Slightly\\nIneffective',\n",
    "                                      'Slightly\\nEffective', 'Moderately\\nEffective', 'Completely\\nEffective'])\n",
    "        sns.heatmap(comp_df, annot=True, fmt='d', cmap='RdYlGn', ax=ax4, cbar_kws={'label': 'Response Count'})\n",
    "        ax4.set_title('Intelligence Data Provision Effectiveness Distribution', fontsize=14, fontweight='bold')\n",
    "        ax4.set_xlabel('Effectiveness Rating')\n",
    "        ax4.set_ylabel('Application')\n",
    "\n",
    "# 5. Provision vs Completion scatter plot\n",
    "ax5 = plt.subplot(4, 3, 7)\n",
    "if avg_scores and avg_completion_scores:\n",
    "    scatter_data = []\n",
    "    for app in set(avg_scores.keys()) & set(avg_completion_scores.keys()):\n",
    "        scatter_data.append({\n",
    "            'app': app,\n",
    "            'provision': avg_scores[app],\n",
    "            'completion': avg_completion_scores[app]\n",
    "        })\n",
    "    \n",
    "    if scatter_data:\n",
    "        scatter_df = pd.DataFrame(scatter_data)\n",
    "        ax5.scatter(scatter_df['provision'], scatter_df['completion'], s=100, alpha=0.6, color=COLORS['primary'])\n",
    "        \n",
    "        # Add labels\n",
    "        for _, row in scatter_df.iterrows():\n",
    "            ax5.annotate(row['app'], (row['provision'], row['completion']), \n",
    "                        xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "        \n",
    "        # Add diagonal line\n",
    "        ax5.plot([0, 6], [0, 6], 'k--', alpha=0.3)\n",
    "        \n",
    "        ax5.set_xlabel('Data Provision Effectiveness')\n",
    "        ax5.set_ylabel('Role Completion Effectiveness')\n",
    "        ax5.set_title('Provision vs Completion Effectiveness', fontsize=14, fontweight='bold')\n",
    "        ax5.set_xlim(0, 6)\n",
    "        ax5.set_ylim(0, 6)\n",
    "        ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Response rate by application\n",
    "ax6 = plt.subplot(4, 3, 8)\n",
    "response_rates = {}\n",
    "for app in intel_apps:\n",
    "    field_name = f'mop_1_1_1.intelligence_data_provided_{app}'\n",
    "    if field_name in df.columns:\n",
    "        total = len(df)\n",
    "        non_na = df[field_name].notna().sum()\n",
    "        response_rates[app.upper()] = (non_na / total) * 100\n",
    "\n",
    "if response_rates:\n",
    "    resp_series = pd.Series(response_rates).sort_values(ascending=True)\n",
    "    resp_series.plot(kind='barh', ax=ax6, color=COLORS['info'])\n",
    "    ax6.set_title('Response Rates by Application', fontsize=14, fontweight='bold')\n",
    "    ax6.set_xlabel('Response Rate (%)')\n",
    "    ax6.set_xlim(0, 100)\n",
    "    for i, (app, rate) in enumerate(resp_series.items()):\n",
    "        ax6.text(rate + 1, i, f'{rate:.1f}%', va='center', fontsize=9)\n",
    "\n",
    "# 7. Top and bottom performers\n",
    "ax7 = plt.subplot(4, 3, 9)\n",
    "if avg_scores:\n",
    "    # Combine provision and completion scores\n",
    "    combined_scores = {}\n",
    "    for app in avg_scores:\n",
    "        prov_score = avg_scores.get(app, 0)\n",
    "        comp_score = avg_completion_scores.get(app, 0) if avg_completion_scores else 0\n",
    "        combined_scores[app] = (prov_score + comp_score) / 2 if comp_score else prov_score\n",
    "    \n",
    "    # Get top 5 and bottom 5\n",
    "    sorted_apps = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_bottom = sorted_apps[:5] + sorted_apps[-5:]\n",
    "    \n",
    "    apps = [app for app, _ in top_bottom]\n",
    "    scores = [score for _, score in top_bottom]\n",
    "    colors = [COLORS['success'] if i < 5 else COLORS['quaternary'] for i in range(len(apps))]\n",
    "    \n",
    "    y_pos = np.arange(len(apps))\n",
    "    ax7.barh(y_pos, scores, color=colors)\n",
    "    ax7.set_yticks(y_pos)\n",
    "    ax7.set_yticklabels(apps)\n",
    "    ax7.set_xlabel('Combined Effectiveness Score')\n",
    "    ax7.set_title('Top 5 and Bottom 5 Applications', fontsize=14, fontweight='bold')\n",
    "    ax7.set_xlim(0, 6)\n",
    "    \n",
    "    for i, score in enumerate(scores):\n",
    "        ax7.text(score + 0.1, i, f'{score:.2f}', va='center', fontsize=9)\n",
    "\n",
    "# 8. Effectiveness distribution\n",
    "ax8 = plt.subplot(4, 3, 10)\n",
    "all_ratings = []\n",
    "for app in intel_apps:\n",
    "    field_name = f'mop_1_1_1.intelligence_data_provided_{app}'\n",
    "    if field_name in df.columns:\n",
    "        ratings = df[field_name].dropna()\n",
    "        all_ratings.extend(ratings.tolist())\n",
    "\n",
    "if all_ratings:\n",
    "    rating_counts = pd.Series(all_ratings).value_counts()\n",
    "    rating_order = ['Completely Ineffective', 'Moderately Ineffective', 'Slightly Ineffective',\n",
    "                   'Slightly Effective', 'Moderately Effective', 'Completely Effective', 'Not Applicable']\n",
    "    rating_counts = rating_counts.reindex(rating_order, fill_value=0)\n",
    "    \n",
    "    colors = [colors_map.get(rating, 'gray') for rating in rating_counts.index]\n",
    "    rating_counts.plot(kind='bar', ax=ax8, color=colors)\n",
    "    ax8.set_title('Overall Rating Distribution', fontsize=14, fontweight='bold')\n",
    "    ax8.set_xlabel('Rating')\n",
    "    ax8.set_ylabel('Count')\n",
    "    ax8.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 9. NA rate comparison\n",
    "ax9 = plt.subplot(4, 3, 11)\n",
    "na_rates = {}\n",
    "for app in intel_apps:\n",
    "    field_name = f'mop_1_1_1.intelligence_data_provided_{app}'\n",
    "    if field_name in df.columns:\n",
    "        na_count = (df[field_name] == 'Not Applicable').sum()\n",
    "        total = df[field_name].notna().sum()\n",
    "        if total > 0:\n",
    "            na_rates[app.upper()] = (na_count / total) * 100\n",
    "\n",
    "if na_rates:\n",
    "    na_series = pd.Series(na_rates).sort_values(ascending=False).head(10)\n",
    "    na_series.plot(kind='bar', ax=ax9, color=COLORS['warning'])\n",
    "    ax9.set_title('\"Not Applicable\" Response Rates (Top 10)', fontsize=14, fontweight='bold')\n",
    "    ax9.set_xlabel('Application')\n",
    "    ax9.set_ylabel('NA Rate (%)')\n",
    "    ax9.tick_params(axis='x', rotation=45)\n",
    "    ax9.set_ylim(0, 100)\n",
    "\n",
    "plt.suptitle('MOP 1.1.1 Intelligence Data Analysis', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "source": "# JCC2 Application Usage Visualizations\nfig = plt.figure(figsize=(20, 16))\n\n# Analyze jcc2_application_usage section\nusage_summary = processor.get_section_summary('jcc2_application_usage')\nprint(\"JCC2 Application Usage Fields:\")\nprint(f\"Total fields: {usage_summary['total_fields']}\")\n\n# Extract application names and usage metrics\napps_in_usage = ['jcc2cyberops', 'jcc2readiness', 'a2it', 'cad', 'codex', 'crucible', \n                 'cyber9line', 'dispatch', 'madss', 'rally', 'redmap', 'sigact', \n                 'threathub', 'triage', 'unity']\n\n# 1. Frequency of use heatmap\nax1 = plt.subplot(3, 3, (1, 3))\nfreq_data = []\nfreq_order = ['Never', 'Daily', 'Weekly', 'Monthly']\napp_labels = []\n\nfor app in apps_in_usage:\n    field = f'jcc2_application_usage.frequency_{app}'\n    if field in df.columns:\n        counts = df[field].value_counts()\n        row = [counts.get(freq, 0) for freq in freq_order]\n        if sum(row) > 0:  # Only include apps with data\n            freq_data.append(row)\n            app_labels.append(app.upper())\n\nif freq_data:\n    freq_df = pd.DataFrame(freq_data, index=app_labels, columns=freq_order)\n    sns.heatmap(freq_df, annot=True, fmt='d', cmap='YlOrRd', ax=ax1, cbar_kws={'label': 'Number of Users'})\n    ax1.set_title('Application Usage Frequency Heatmap', fontsize=14, fontweight='bold')\n    ax1.set_xlabel('Frequency')\n    ax1.set_ylabel('Application')\n\n# 2. Training received by application\nax2 = plt.subplot(3, 3, 4)\ntraining_data = {}\nfor app in apps_in_usage:\n    field = f'jcc2_application_usage.training_received_{app}'\n    if field in df.columns:\n        yes_count = (df[field] == 'Yes').sum()\n        no_count = (df[field] == 'No').sum()\n        if yes_count + no_count > 0:\n            training_data[app.upper()] = yes_count / (yes_count + no_count) * 100\n\nif training_data:\n    training_series = pd.Series(training_data).sort_values(ascending=True)\n    training_series.plot(kind='barh', ax=ax2, color=COLORS['success'])\n    ax2.set_title('Training Received by Application', fontsize=14, fontweight='bold')\n    ax2.set_xlabel('% Users Trained')\n    ax2.set_xlim(0, 100)\n    for i, (app, pct) in enumerate(training_series.items()):\n        ax2.text(pct + 1, i, f'{pct:.1f}%', va='center', fontsize=9)\n\n# 3. Classification levels used\nax3 = plt.subplot(3, 3, 5)\nclass_levels = ['NIPR', 'SIPR', 'JWICS']\nclass_counts = {level: 0 for level in class_levels}\n\nfor app in apps_in_usage:\n    field = f'jcc2_application_usage.classification_{app}'\n    if field in df.columns:\n        for _, value in df[field].dropna().items():\n            if isinstance(value, list):\n                for level in value:\n                    if level in class_levels:\n                        class_counts[level] += 1\n            elif isinstance(value, str):\n                for level in value.split('; '):\n                    if level in class_levels:\n                        class_counts[level] += 1\n\nif any(class_counts.values()):\n    pd.Series(class_counts).plot(kind='pie', ax=ax3, autopct='%1.1f%%', startangle=90,\n                                colors=[COLORS['info'], COLORS['warning'], COLORS['quaternary']])\n    ax3.set_title('Classification Levels Usage', fontsize=14, fontweight='bold')\n    ax3.set_ylabel('')\n\n# 4. Daily users by application\nax4 = plt.subplot(3, 3, 6)\ndaily_users = {}\nfor app in apps_in_usage:\n    field = f'jcc2_application_usage.frequency_{app}'\n    if field in df.columns:\n        daily_count = (df[field] == 'Daily').sum()\n        if daily_count > 0:\n            daily_users[app.upper()] = daily_count\n\nif daily_users:\n    daily_series = pd.Series(daily_users).sort_values(ascending=False).head(10)\n    daily_series.plot(kind='bar', ax=ax4, color=COLORS['primary'])\n    ax4.set_title('Applications with Daily Users', fontsize=14, fontweight='bold')\n    ax4.set_ylabel('Number of Daily Users')\n    ax4.tick_params(axis='x', rotation=45)\n\n# 5. Training type distribution\nax5 = plt.subplot(3, 3, 7)\ntraining_types = []\nfor app in apps_in_usage:\n    field = f'jcc2_application_usage.training_type_{app}'\n    if field in df.columns:\n        types = df[field].dropna()\n        training_types.extend(types.tolist())\n\nif training_types:\n    # Simple categorization of training types\n    type_categories = {\n        'Formal': 0, 'On-the-job': 0, 'Self-taught': 0, \n        'Peer': 0, 'Documentation': 0, 'Other': 0\n    }\n    \n    for training in training_types:\n        training_lower = str(training).lower()\n        categorized = False\n        for category in type_categories:\n            if category.lower() in training_lower:\n                type_categories[category] += 1\n                categorized = True\n                break\n        if not categorized:\n            type_categories['Other'] += 1\n    \n    type_series = pd.Series(type_categories)\n    type_series[type_series > 0].plot(kind='bar', ax=ax5, color=COLORS['tertiary'])\n    ax5.set_title('Training Type Distribution', fontsize=14, fontweight='bold')\n    ax5.set_ylabel('Count')\n    ax5.tick_params(axis='x', rotation=45)\n\n# 6. Usage vs Training correlation\nax6 = plt.subplot(3, 3, 8)\nusage_training_data = []\nfor app in apps_in_usage[:10]:  # Top 10 for clarity\n    freq_field = f'jcc2_application_usage.frequency_{app}'\n    train_field = f'jcc2_application_usage.training_received_{app}'\n    \n    if freq_field in df.columns and train_field in df.columns:\n        # Calculate usage score (Never=0, Monthly=1, Weekly=2, Daily=3)\n        usage_map = {'Never': 0, 'Monthly': 1, 'Weekly': 2, 'Daily': 3}\n        avg_usage = df[freq_field].map(usage_map).mean()\n        \n        # Calculate training percentage\n        train_pct = (df[train_field] == 'Yes').mean() * 100\n        \n        if pd.notna(avg_usage) and pd.notna(train_pct):\n            usage_training_data.append({\n                'app': app.upper(),\n                'usage_score': avg_usage,\n                'training_pct': train_pct\n            })\n\nif usage_training_data:\n    ut_df = pd.DataFrame(usage_training_data)\n    ax6.scatter(ut_df['training_pct'], ut_df['usage_score'], s=100, alpha=0.6, color=COLORS['primary'])\n    \n    for _, row in ut_df.iterrows():\n        ax6.annotate(row['app'], (row['training_pct'], row['usage_score']), \n                    xytext=(5, 5), textcoords='offset points', fontsize=8)\n    \n    ax6.set_xlabel('Training Received (%)')\n    ax6.set_ylabel('Average Usage Score (0-3)')\n    ax6.set_title('Training vs Usage Correlation', fontsize=14, fontweight='bold')\n    ax6.grid(True, alpha=0.3)\n\n# 7. Application adoption summary\nax7 = plt.subplot(3, 3, 9)\nadoption_summary = []\nfor app in apps_in_usage:\n    freq_field = f'jcc2_application_usage.frequency_{app}'\n    if freq_field in df.columns:\n        never_count = (df[freq_field] == 'Never').sum()\n        total = df[freq_field].notna().sum()\n        if total > 0:\n            adoption_rate = (total - never_count) / total * 100\n            adoption_summary.append({\n                'app': app.upper(),\n                'adoption': adoption_rate\n            })\n\nif adoption_summary:\n    adopt_df = pd.DataFrame(adoption_summary).sort_values('adoption', ascending=False).head(10)\n    adopt_df.plot(x='app', y='adoption', kind='bar', ax=ax7, color=COLORS['success'], legend=False)\n    ax7.set_title('Top 10 Applications by Adoption Rate', fontsize=14, fontweight='bold')\n    ax7.set_xlabel('Application')\n    ax7.set_ylabel('Adoption Rate (%)')\n    ax7.tick_params(axis='x', rotation=45)\n    ax7.set_ylim(0, 100)\n\nplt.suptitle('JCC2 Application Usage Analysis', fontsize=16, fontweight='bold')\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 6. MOS 1.1.2 Object Tagging and Correlation Analysis",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## 10. Summary Dashboard",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Create a comprehensive summary dashboard combining key insights from ALL sections\nfig = plt.figure(figsize=(24, 20))\n\n# Get all sections for complete analysis\nall_sections = list(processor.sections.keys())\nprint(f\"Total sections analyzed: {len(all_sections)}\")\n\n# 1. Section completion overview (expanded)\nax1 = plt.subplot(4, 3, 1)\nsection_completion = {}\nfor section in all_sections[:15]:  # Top 15 sections\n    if section in processor.sections:\n        fields = processor.sections[section]\n        completion_rates = [df[field].notna().mean() for field in fields if field in df.columns]\n        section_completion[section] = np.mean(completion_rates) if completion_rates else 0\n\ncomp_series = pd.Series(section_completion).sort_values(ascending=True)\ncomp_series.plot(kind='barh', ax=ax1, color=COLORS['primary'])\nax1.set_title('Completion Rates by Section (Top 15)', fontsize=14, fontweight='bold')\nax1.set_xlabel('Completion Rate')\nax1.set_xlim(0, 1)\nfor i, (section, rate) in enumerate(comp_series.items()):\n    ax1.text(rate + 0.02, i, f'{rate:.1%}', va='center', fontweight='bold', fontsize=9)\n\n# 2. Overall effectiveness scores by category\nax2 = plt.subplot(4, 3, 2)\ncategory_scores = {\n    'Intelligence Data (MOP 1.1.1)': 0,\n    'Object Tracking (MOS 1.1.2)': 0,\n    'Reporting & Export': 0,\n    'System Usability (SUS)': 0,\n    'System Suitability': 0\n}\n\n# Calculate average scores for each category\nmop_fields = [col for col in df.columns if col.startswith('mop_1_1_1') and 'effectiveness' in col]\nif mop_fields:\n    all_ratings = []\n    for field in mop_fields:\n        ratings = df[field].map(effectiveness_map).dropna()\n        all_ratings.extend(ratings[ratings > 0].tolist())\n    if all_ratings:\n        category_scores['Intelligence Data (MOP 1.1.1)'] = np.mean(all_ratings)\n\nmos_fields = [col for col in df.columns if col.startswith('mos_1_1_2') and 'suitability' in col]\nif mos_fields:\n    all_ratings = []\n    for field in mos_fields:\n        ratings = df[field].map(suitability_map).dropna()\n        all_ratings.extend(ratings[ratings > 0].tolist())\n    if all_ratings:\n        category_scores['Object Tracking (MOS 1.1.2)'] = np.mean(all_ratings)\n\nif sus_scores:\n    category_scores['System Usability (SUS)'] = np.mean(sus_scores) / 100 * 6  # Convert to 6-point scale\n\ncat_series = pd.Series({k: v for k, v in category_scores.items() if v > 0})\nif not cat_series.empty:\n    cat_series.plot(kind='bar', ax=ax2, color=COLORS['secondary'])\n    ax2.set_title('Average Scores by Category', fontsize=14, fontweight='bold')\n    ax2.set_ylabel('Score (1-6 scale)')\n    ax2.set_ylim(0, 6)\n    ax2.tick_params(axis='x', rotation=45)\n    ax2.axhline(3.5, color='red', linestyle='--', alpha=0.5, label='Neutral')\n\n# 3. Application ecosystem overview\nax3 = plt.subplot(4, 3, 3)\napp_metrics = {}\nmain_apps = ['a2it', 'cad', 'codex', 'crucible', 'cyber9line', 'dispatch', \n             'jcc2cyberops', 'jcc2readiness', 'madss', 'rally', 'redmap', \n             'sigact', 'threathub', 'triage', 'unity']\n\nfor app in main_apps:\n    exp_field = f'operational_jcc2_experience.exp_app_{app}'\n    freq_field = f'jcc2_application_usage.frequency_{app}'\n    \n    if exp_field in df.columns:\n        # Calculate adoption (not NA)\n        exp_data = df[exp_field].value_counts()\n        adoption = 1 - (exp_data.get('NA', 0) / exp_data.sum()) if exp_data.sum() > 0 else 0\n        \n        # Calculate usage intensity\n        if freq_field in df.columns:\n            freq_map = {'Never': 0, 'Monthly': 1, 'Weekly': 2, 'Daily': 3}\n            usage = df[freq_field].map(freq_map).mean() / 3 if freq_field in df.columns else 0\n        else:\n            usage = 0\n        \n        app_metrics[app.upper()] = (adoption + usage) / 2\n\nif app_metrics:\n    top_apps = pd.Series(app_metrics).sort_values(ascending=False).head(10)\n    top_apps.plot(kind='bar', ax=ax3, color=COLORS['tertiary'])\n    ax3.set_title('Top 10 Applications by Combined Metric', fontsize=14, fontweight='bold')\n    ax3.set_xlabel('Application')\n    ax3.set_ylabel('Score (0-1)')\n    ax3.tick_params(axis='x', rotation=45)\n\n# 4. Response quality heatmap\nax4 = plt.subplot(4, 3, (4, 6))\nquality_matrix = []\nsection_names = []\nsample_sections = ['user_information', 'role_and_echelon', 'operational_jcc2_experience', \n                   'jcc2_application_usage', 'mop_1_1_1', 'mos_1_1_2', \n                   'reporting_and_data_export', 'overall_system_usability', \n                   'overall_system_suitability_eval']\n\nfor section in sample_sections:\n    if section in processor.sections:\n        section_names.append(section.replace('_', ' ').title()[:20])\n        fields = processor.sections[section]\n        row = []\n        for field in fields[:15]:  # First 15 fields\n            if field in df.columns:\n                row.append(df[field].notna().mean())\n        while len(row) < 15:\n            row.append(0)\n        quality_matrix.append(row)\n\nif quality_matrix:\n    quality_df = pd.DataFrame(quality_matrix, index=section_names)\n    sns.heatmap(quality_df, annot=False, cmap='RdYlGn', ax=ax4, \n                cbar_kws={'label': 'Completion Rate'}, vmin=0, vmax=1)\n    ax4.set_title('Data Quality Heatmap - Key Sections', fontsize=14, fontweight='bold')\n    ax4.set_xlabel('Field Index')\n    ax4.set_ylabel('Section')\n\n# 5. User demographics summary\nax5 = plt.subplot(4, 3, 7)\ndemo_data = []\nif 'user_information.event' in df.columns:\n    demo_data.append(['Unique Events', df['user_information.event'].nunique()])\nif 'user_information.unit' in df.columns:\n    demo_data.append(['Unique Units', df['user_information.unit'].nunique()])\nif 'role_and_echelon.is_cyber_operator' in df.columns:\n    demo_data.append(['Cyber Operators', (df['role_and_echelon.is_cyber_operator'] == 'Yes').sum()])\ndemo_data.append(['Total Responses', len(df)])\n\nif demo_data:\n    demo_df = pd.DataFrame(demo_data, columns=['Metric', 'Count'])\n    ax5.bar(demo_df['Metric'], demo_df['Count'], color=COLORS['info'])\n    ax5.set_title('User Demographics Summary', fontsize=14, fontweight='bold')\n    ax5.set_ylabel('Count')\n    ax5.tick_params(axis='x', rotation=45)\n    for i, (metric, count) in enumerate(demo_df.values):\n        ax5.text(i, count + 0.5, str(count), ha='center', fontweight='bold')\n\n# 6. System evaluation overview\nax6 = plt.subplot(4, 3, 8)\neval_metrics = []\nif sus_scores:\n    eval_metrics.append(['Avg SUS Score', np.mean(sus_scores), 68])  # 68 is acceptable threshold\nif 'nps_score' in locals():\n    eval_metrics.append(['NPS Score', nps_score + 50, 50])  # Shift to 0-100 scale\nif satisfaction_metrics:\n    eval_metrics.append(['Satisfaction %', satisfaction_metrics.get('Satisfaction Rate', 0), 70])\n\nif eval_metrics:\n    labels = [m[0] for m in eval_metrics]\n    values = [m[1] for m in eval_metrics]\n    thresholds = [m[2] for m in eval_metrics]\n    \n    x = np.arange(len(labels))\n    bars = ax6.bar(x, values, color=COLORS['primary'])\n    \n    # Add threshold lines\n    for i, thresh in enumerate(thresholds):\n        ax6.hlines(thresh, i-0.4, i+0.4, colors='red', linestyles='--', linewidth=2)\n    \n    ax6.set_xticks(x)\n    ax6.set_xticklabels(labels)\n    ax6.set_title('System Evaluation Metrics', fontsize=14, fontweight='bold')\n    ax6.set_ylabel('Score')\n    ax6.set_ylim(0, 100)\n    \n    for i, (bar, value) in enumerate(zip(bars, values)):\n        ax6.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n                f'{value:.1f}', ha='center', fontweight='bold')\n\n# 7. Experience distribution overview\nax7 = plt.subplot(4, 3, 9)\nexp_summary = {'< 1 Year': 0, '1-3 Years': 0, '3-5 Years': 0, '> 5 Years': 0, 'NA': 0}\nexp_fields = [col for col in df.columns if 'operational_jcc2_experience.exp_' in col]\nfor field in exp_fields:\n    counts = df[field].value_counts()\n    for exp_level in exp_summary:\n        exp_summary[exp_level] += counts.get(exp_level, 0)\n\n# Remove NA for cleaner visualization\nexp_summary.pop('NA', None)\nexp_series = pd.Series(exp_summary)\nexp_series.plot(kind='pie', ax=ax7, autopct='%1.1f%%', startangle=90, \n                colors=[COLORS['info'], COLORS['primary'], COLORS['tertiary'], COLORS['success']])\nax7.set_title('Overall Experience Distribution', fontsize=14, fontweight='bold')\nax7.set_ylabel('')\n\n# 8. Key insights summary\nax8 = plt.subplot(4, 3, 10)\n# Calculate key insights\ntotal_fields = sum(len(fields) for fields in processor.sections.values())\navg_completion = df.notna().sum().sum() / (len(df) * len(df.columns)) * 100\ntop_section = max(section_completion.items(), key=lambda x: x[1])[0] if section_completion else 'N/A'\n\ninsight_data = [\n    ['Total Sections', len(all_sections)],\n    ['Total Fields', total_fields],\n    ['Avg Field Completion', f'{avg_completion:.1f}%'],\n    ['Most Complete Section', top_section[:20]],\n    ['Top Application', top_apps.index[0] if len(top_apps) > 0 else 'N/A']\n]\n\nax8.axis('off')\ntable = ax8.table(cellText=insight_data, \n                  colLabels=['Metric', 'Value'],\n                  cellLoc='left',\n                  loc='center',\n                  colWidths=[0.6, 0.4])\ntable.auto_set_font_size(False)\ntable.set_fontsize(10)\ntable.scale(1, 1.5)\nax8.set_title('Key Dataset Insights', fontsize=14, fontweight='bold', y=0.95)\n\n# 9. Response timeline\nax9 = plt.subplot(4, 3, 11)\nif 'user_information.date' in df.columns:\n    df['month_year'] = pd.to_datetime(df['user_information.date']).dt.to_period('M')\n    monthly_counts = df['month_year'].value_counts().sort_index()\n    monthly_counts.index = monthly_counts.index.to_timestamp()\n    \n    monthly_counts.plot(kind='line', ax=ax9, color=COLORS['secondary'], marker='o', linewidth=2)\n    ax9.fill_between(monthly_counts.index, monthly_counts.values, alpha=0.3, color=COLORS['secondary'])\n    ax9.set_title('Response Collection Timeline', fontsize=14, fontweight='bold')\n    ax9.set_xlabel('Month')\n    ax9.set_ylabel('Number of Responses')\n    ax9.grid(True, alpha=0.3)\n\n# 10. Analysis coverage summary\nax10 = plt.subplot(4, 3, 12)\ncoverage_data = {\n    'Demographics': ['user_information', 'role_and_echelon'],\n    'Experience': ['operational_jcc2_experience', 'jcc2_application_usage'],\n    'Performance': [s for s in all_sections if s.startswith('mop')],\n    'Suitability': [s for s in all_sections if s.startswith('mos')],\n    'System Eval': ['overall_system_usability', 'overall_system_suitability_eval', 'reporting_and_data_export']\n}\n\ncoverage_counts = {cat: len(sections) for cat, sections in coverage_data.items()}\ncoverage_series = pd.Series(coverage_counts)\n\ncoverage_series.plot(kind='bar', ax=ax10, color=COLORS['quaternary'])\nax10.set_title('Section Coverage by Category', fontsize=14, fontweight='bold')\nax10.set_xlabel('Category')\nax10.set_ylabel('Number of Sections')\nax10.tick_params(axis='x', rotation=45)\n\nfor i, (cat, count) in enumerate(coverage_series.items()):\n    ax10.text(i, count + 0.1, str(count), ha='center', fontweight='bold')\n\nplt.suptitle('JCC2 User Questionnaire - Comprehensive Analysis Dashboard', fontsize=20, fontweight='bold')\nplt.tight_layout()\nplt.show()",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Reporting and Data Export Visualizations\nfig = plt.figure(figsize=(20, 16))\n\n# Analyze reporting_and_data_export section\nreport_summary = processor.get_section_summary('reporting_and_data_export')\nprint(\"Reporting and Data Export Fields:\")\nprint(f\"Total fields: {report_summary['total_fields']}\")\n\n# 1. Report generation effectiveness\nax1 = plt.subplot(3, 3, 1)\nreport_gen_fields = [col for col in df.columns if col.startswith('reporting_and_data_export.report_generation_effectiveness')]\nreport_apps = []\nreport_scores = {}\n\nfor field in report_gen_fields:\n    app_name = field.split('_')[-1].upper()\n    if field in df.columns:\n        ratings = df[field].dropna()\n        if len(ratings) > 0:\n            numeric_ratings = ratings.map(effectiveness_map).fillna(0)\n            valid_ratings = numeric_ratings[numeric_ratings > 0]\n            if len(valid_ratings) > 0:\n                report_scores[app_name] = valid_ratings.mean()\n\nif report_scores:\n    report_series = pd.Series(report_scores).sort_values(ascending=True)\n    report_series.plot(kind='barh', ax=ax1, color=COLORS['primary'])\n    ax1.set_title('Report Generation Effectiveness by Application', fontsize=14, fontweight='bold')\n    ax1.set_xlabel('Average Effectiveness Score (1-6)')\n    ax1.set_xlim(0, 6)\n    for i, (app, score) in enumerate(report_series.items()):\n        ax1.text(score + 0.1, i, f'{score:.2f}', va='center', fontsize=9)\n\n# 2. Data export effectiveness\nax2 = plt.subplot(3, 3, 2)\nexport_fields = [col for col in df.columns if col.startswith('reporting_and_data_export.data_export_effectiveness')]\nexport_scores = {}\n\nfor field in export_fields:\n    app_name = field.split('_')[-1].upper()\n    if field in df.columns:\n        ratings = df[field].dropna()\n        if len(ratings) > 0:\n            numeric_ratings = ratings.map(effectiveness_map).fillna(0)\n            valid_ratings = numeric_ratings[numeric_ratings > 0]\n            if len(valid_ratings) > 0:\n                export_scores[app_name] = valid_ratings.mean()\n\nif export_scores:\n    export_series = pd.Series(export_scores).sort_values(ascending=True)\n    export_series.plot(kind='barh', ax=ax2, color=COLORS['secondary'])\n    ax2.set_title('Data Export Effectiveness by Application', fontsize=14, fontweight='bold')\n    ax2.set_xlabel('Average Effectiveness Score (1-6)')\n    ax2.set_xlim(0, 6)\n    for i, (app, score) in enumerate(export_series.items()):\n        ax2.text(score + 0.1, i, f'{score:.2f}', va='center', fontsize=9)\n\n# 3. Overall reporting effectiveness\nax3 = plt.subplot(3, 3, 3)\nif 'reporting_and_data_export.overall_reporting_effectiveness' in df.columns:\n    overall_report = df['reporting_and_data_export.overall_reporting_effectiveness'].value_counts()\n    colors = [colors_map.get(rating, 'gray') for rating in overall_report.index]\n    overall_report.plot(kind='pie', ax=ax3, autopct='%1.1f%%', colors=colors, startangle=90)\n    ax3.set_title('Overall Reporting Effectiveness', fontsize=14, fontweight='bold')\n    ax3.set_ylabel('')\n\n# 4. Report vs Export comparison\nax4 = plt.subplot(3, 3, 4)\nif report_scores and export_scores:\n    comparison_data = []\n    for app in set(report_scores.keys()) & set(export_scores.keys()):\n        comparison_data.append({\n            'app': app,\n            'report': report_scores[app],\n            'export': export_scores[app]\n        })\n    \n    if comparison_data:\n        comp_df = pd.DataFrame(comparison_data)\n        ax4.scatter(comp_df['report'], comp_df['export'], s=100, alpha=0.6, color=COLORS['primary'])\n        \n        for _, row in comp_df.iterrows():\n            ax4.annotate(row['app'], (row['report'], row['export']), \n                        xytext=(5, 5), textcoords='offset points', fontsize=8)\n        \n        ax4.plot([0, 6], [0, 6], 'k--', alpha=0.3)\n        ax4.set_xlabel('Report Generation Effectiveness')\n        ax4.set_ylabel('Data Export Effectiveness')\n        ax4.set_title('Report Generation vs Data Export', fontsize=14, fontweight='bold')\n        ax4.set_xlim(0, 6)\n        ax4.set_ylim(0, 6)\n        ax4.grid(True, alpha=0.3)\n\n# 5. Export format preferences\nax5 = plt.subplot(3, 3, 5)\nformat_fields = [col for col in df.columns if 'export_format' in col]\nformat_counts = {'CSV': 0, 'Excel': 0, 'PDF': 0, 'JSON': 0, 'XML': 0, 'Other': 0}\n\nfor field in format_fields:\n    if field in df.columns:\n        formats = df[field].dropna()\n        for fmt in formats:\n            fmt_str = str(fmt).upper()\n            found = False\n            for key in format_counts:\n                if key in fmt_str:\n                    format_counts[key] += 1\n                    found = True\n                    break\n            if not found:\n                format_counts['Other'] += 1\n\nif any(format_counts.values()):\n    format_series = pd.Series({k: v for k, v in format_counts.items() if v > 0})\n    format_series.plot(kind='bar', ax=ax5, color=COLORS['tertiary'])\n    ax5.set_title('Export Format Preferences', fontsize=14, fontweight='bold')\n    ax5.set_xlabel('Format')\n    ax5.set_ylabel('Count')\n    ax5.tick_params(axis='x', rotation=45)\n\n# 6. Reporting frequency needs\nax6 = plt.subplot(3, 3, 6)\nfreq_fields = [col for col in df.columns if 'reporting_frequency' in col]\nfreq_counts = {'Real-time': 0, 'Daily': 0, 'Weekly': 0, 'Monthly': 0, 'On-demand': 0}\n\nfor field in freq_fields:\n    if field in df.columns:\n        frequencies = df[field].dropna()\n        for freq in frequencies:\n            freq_str = str(freq).lower()\n            for key in freq_counts:\n                if key.lower() in freq_str:\n                    freq_counts[key] += 1\n                    break\n\nif any(freq_counts.values()):\n    freq_series = pd.Series({k: v for k, v in freq_counts.items() if v > 0})\n    freq_series.plot(kind='pie', ax=ax6, autopct='%1.1f%%', startangle=90)\n    ax6.set_title('Reporting Frequency Needs', fontsize=14, fontweight='bold')\n    ax6.set_ylabel('')\n\n# 7. Combined effectiveness ranking\nax7 = plt.subplot(3, 3, 7)\ncombined_report_scores = {}\nfor app in set(report_scores.keys()) | set(export_scores.keys()):\n    rep_score = report_scores.get(app, 0)\n    exp_score = export_scores.get(app, 0)\n    if rep_score > 0 or exp_score > 0:\n        combined_report_scores[app] = (rep_score + exp_score) / 2\n\nif combined_report_scores:\n    sorted_apps = sorted(combined_report_scores.items(), key=lambda x: x[1], reverse=True)\n    top_apps = sorted_apps[:10]\n    \n    apps = [app for app, _ in top_apps]\n    scores = [score for _, score in top_apps]\n    \n    y_pos = np.arange(len(apps))\n    ax7.barh(y_pos, scores, color=COLORS['info'])\n    ax7.set_yticks(y_pos)\n    ax7.set_yticklabels(apps)\n    ax7.set_xlabel('Combined Effectiveness Score')\n    ax7.set_title('Top 10 Applications for Reporting/Export', fontsize=14, fontweight='bold')\n    ax7.set_xlim(0, 6)\n    \n    for i, score in enumerate(scores):\n        ax7.text(score + 0.1, i, f'{score:.2f}', va='center', fontsize=9)\n\n# 8. Response rates\nax8 = plt.subplot(3, 3, 8)\nresponse_rates = {}\nall_apps = set()\nfor field in report_gen_fields + export_fields:\n    if field in df.columns:\n        app_name = field.split('_')[-1].upper()\n        all_apps.add(app_name)\n        \nfor app in all_apps:\n    total_responses = 0\n    total_possible = 0\n    for field_type in ['report_generation_effectiveness', 'data_export_effectiveness']:\n        field = f'reporting_and_data_export.{field_type}_{app.lower()}'\n        if field in df.columns:\n            total_responses += df[field].notna().sum()\n            total_possible += len(df)\n    \n    if total_possible > 0:\n        response_rates[app] = (total_responses / total_possible) * 100\n\nif response_rates:\n    resp_series = pd.Series(response_rates).sort_values(ascending=True).head(10)\n    resp_series.plot(kind='barh', ax=ax8, color=COLORS['warning'])\n    ax8.set_title('Response Rates by Application', fontsize=14, fontweight='bold')\n    ax8.set_xlabel('Average Response Rate (%)')\n    ax8.set_xlim(0, 100)\n    for i, (app, rate) in enumerate(resp_series.items()):\n        ax8.text(rate + 1, i, f'{rate:.1f}%', va='center', fontsize=9)\n\n# 9. Effectiveness distribution\nax9 = plt.subplot(3, 3, 9)\nall_ratings = []\nfor field in report_gen_fields + export_fields:\n    if field in df.columns:\n        ratings = df[field].dropna()\n        all_ratings.extend(ratings.tolist())\n\nif all_ratings:\n    rating_counts = pd.Series(all_ratings).value_counts()\n    rating_order = ['Completely Ineffective', 'Moderately Ineffective', 'Slightly Ineffective',\n                   'Slightly Effective', 'Moderately Effective', 'Completely Effective', 'Not Applicable']\n    rating_counts = rating_counts.reindex(rating_order, fill_value=0)\n    \n    colors = [colors_map.get(rating, 'gray') for rating in rating_counts.index]\n    rating_counts.plot(kind='bar', ax=ax9, color=colors)\n    ax9.set_title('Overall Rating Distribution', fontsize=14, fontweight='bold')\n    ax9.set_xlabel('Rating')\n    ax9.set_ylabel('Count')\n    ax9.tick_params(axis='x', rotation=45)\n\nplt.suptitle('Reporting and Data Export Analysis', fontsize=16, fontweight='bold')\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 8. Overall System Usability Section Analysis",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Overall System Usability Visualizations\nfig = plt.figure(figsize=(20, 16))\n\n# Analyze overall_system_usability section\nusability_summary = processor.get_section_summary('overall_system_usability')\nprint(\"Overall System Usability Fields:\")\nprint(f\"Total fields: {usability_summary['total_fields']}\")\n\n# SUS Score Mapping\nsus_mapping = {\n    'Strongly Disagree': 1,\n    'Disagree': 2,\n    'Neutral': 3,\n    'Agree': 4,\n    'Strongly Agree': 5\n}\n\n# 1. Calculate and visualize SUS scores\nax1 = plt.subplot(3, 3, 1)\n\n# SUS questions\nsus_questions = [\n    'system_use_frequently', 'system_unnecessarily_complex',\n    'system_easy_to_use', 'need_technical_support',\n    'functions_well_integrated', 'too_much_inconsistency',\n    'learn_quickly', 'cumbersome_to_use',\n    'confident_using_system', 'need_to_learn_before_using'\n]\n\n# Calculate individual SUS scores\nsus_scores = []\nfor idx, row in df.iterrows():\n    score = 0\n    valid_responses = 0\n    \n    for i, question in enumerate(sus_questions):\n        field = f'overall_system_usability.{question}'\n        if field in df.columns and pd.notna(row[field]):\n            response_value = sus_mapping.get(row[field], 0)\n            if response_value > 0:\n                # Odd questions (positive): score - 1\n                # Even questions (negative): 5 - score\n                if i % 2 == 0:\n                    score += response_value - 1\n                else:\n                    score += 5 - response_value\n                valid_responses += 1\n    \n    if valid_responses == 10:  # Only include complete responses\n        sus_scores.append(score * 2.5)  # Convert to 0-100 scale\n\nif sus_scores:\n    sus_series = pd.Series(sus_scores)\n    sus_series.hist(bins=20, ax=ax1, color=COLORS['primary'], edgecolor='black', alpha=0.7)\n    ax1.axvline(sus_series.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {sus_series.mean():.1f}')\n    ax1.axvline(68, color='green', linestyle='--', linewidth=2, label='Acceptable: 68')\n    ax1.set_title('System Usability Scale (SUS) Score Distribution', fontsize=14, fontweight='bold')\n    ax1.set_xlabel('SUS Score (0-100)')\n    ax1.set_ylabel('Number of Respondents')\n    ax1.legend()\n    ax1.grid(True, alpha=0.3)\n\n# 2. SUS grade distribution\nax2 = plt.subplot(3, 3, 2)\nif sus_scores:\n    # Convert SUS scores to grades\n    def sus_to_grade(score):\n        if score >= 80.3: return 'A'\n        elif score >= 68: return 'B'\n        elif score >= 51: return 'C'\n        elif score >= 31: return 'D'\n        else: return 'F'\n    \n    grades = [sus_to_grade(score) for score in sus_scores]\n    grade_counts = pd.Series(grades).value_counts()\n    grade_colors = {'A': COLORS['success'], 'B': COLORS['info'], 'C': COLORS['primary'], \n                   'D': COLORS['warning'], 'F': COLORS['quaternary']}\n    colors = [grade_colors[grade] for grade in grade_counts.index]\n    \n    grade_counts.plot(kind='pie', ax=ax2, autopct='%1.1f%%', colors=colors, startangle=90)\n    ax2.set_title('SUS Grade Distribution', fontsize=14, fontweight='bold')\n    ax2.set_ylabel('')\n\n# 3. Individual question responses\nax3 = plt.subplot(3, 3, (3, 6))\nquestion_data = []\nquestion_labels = [\n    'Use Frequently', 'Not Complex', 'Easy to Use', 'No Tech Support',\n    'Well Integrated', 'Consistent', 'Learn Quickly', 'Not Cumbersome',\n    'Confident', 'No Prior Learning'\n]\n\nfor i, (question, label) in enumerate(zip(sus_questions, question_labels)):\n    field = f'overall_system_usability.{question}'\n    if field in df.columns:\n        counts = df[field].value_counts()\n        row = [counts.get(resp, 0) for resp in ['Strongly Disagree', 'Disagree', 'Neutral', 'Agree', 'Strongly Agree']]\n        question_data.append(row)\n\nif question_data:\n    question_df = pd.DataFrame(question_data, index=question_labels,\n                              columns=['Strongly\\nDisagree', 'Disagree', 'Neutral', 'Agree', 'Strongly\\nAgree'])\n    sns.heatmap(question_df, annot=True, fmt='d', cmap='RdYlGn', ax=ax3, cbar_kws={'label': 'Response Count'})\n    ax3.set_title('Response Distribution by SUS Question', fontsize=14, fontweight='bold')\n    ax3.set_xlabel('Response')\n    ax3.set_ylabel('Question')\n\n# 4. Additional usability comments word cloud (simplified)\nax4 = plt.subplot(3, 3, 7)\nif 'overall_system_usability.additional_comments' in df.columns:\n    comments = df['overall_system_usability.additional_comments'].dropna()\n    if not comments.empty:\n        # Simple word frequency\n        all_words = ' '.join(comments.astype(str)).lower().split()\n        word_freq = pd.Series(all_words).value_counts().head(20)\n        word_freq.plot(kind='barh', ax=ax4, color=COLORS['tertiary'])\n        ax4.set_title('Most Frequent Words in Comments', fontsize=14, fontweight='bold')\n        ax4.set_xlabel('Frequency')\n    else:\n        ax4.text(0.5, 0.5, 'No additional comments', ha='center', va='center', transform=ax4.transAxes)\nelse:\n    ax4.text(0.5, 0.5, 'No comments field found', ha='center', va='center', transform=ax4.transAxes)\n\n# 5. SUS score by experience level (if available)\nax5 = plt.subplot(3, 3, 8)\nif sus_scores and 'operational_jcc2_experience.exp_jcc2experience' in df.columns:\n    exp_sus_data = []\n    for idx, score in enumerate(sus_scores):\n        if idx < len(df):\n            exp_level = df.iloc[idx]['operational_jcc2_experience.exp_jcc2experience']\n            if pd.notna(exp_level):\n                exp_sus_data.append({'experience': exp_level, 'sus_score': score})\n    \n    if exp_sus_data:\n        exp_sus_df = pd.DataFrame(exp_sus_data)\n        exp_grouped = exp_sus_df.groupby('experience')['sus_score'].agg(['mean', 'std', 'count'])\n        exp_order = ['< 1 Year', '1-3 Years', '3-5 Years', '> 5 Years']\n        exp_grouped = exp_grouped.reindex(exp_order)\n        \n        exp_grouped['mean'].plot(kind='bar', ax=ax5, yerr=exp_grouped['std'], \n                                capsize=5, color=COLORS['primary'], alpha=0.7)\n        ax5.axhline(68, color='green', linestyle='--', alpha=0.5, label='Acceptable')\n        ax5.set_title('SUS Score by JCC2 Experience Level', fontsize=14, fontweight='bold')\n        ax5.set_xlabel('Experience Level')\n        ax5.set_ylabel('Average SUS Score')\n        ax5.set_ylim(0, 100)\n        ax5.legend()\n        ax5.tick_params(axis='x', rotation=45)\n\n# 6. Usability metrics summary\nax6 = plt.subplot(3, 3, 9)\nax6.axis('off')\nif sus_scores:\n    metrics_text = f\"\"\"\nSUS Score Metrics:\n\nMean Score: {np.mean(sus_scores):.1f}\nMedian Score: {np.median(sus_scores):.1f}\nStd Deviation: {np.std(sus_scores):.1f}\n\nScore Range: {min(sus_scores):.1f} - {max(sus_scores):.1f}\nAbove Acceptable (68): {sum(s >= 68 for s in sus_scores)} ({sum(s >= 68 for s in sus_scores)/len(sus_scores)*100:.1f}%)\nGrade A (80.3+): {sum(s >= 80.3 for s in sus_scores)} ({sum(s >= 80.3 for s in sus_scores)/len(sus_scores)*100:.1f}%)\n\nTotal Responses: {len(sus_scores)}\n\"\"\"\n    ax6.text(0.1, 0.5, metrics_text, transform=ax6.transAxes, fontsize=12, \n             verticalalignment='center', fontfamily='monospace',\n             bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.5))\nelse:\n    ax6.text(0.5, 0.5, 'Insufficient data for SUS analysis', ha='center', va='center', transform=ax6.transAxes)\n\nplt.suptitle('Overall System Usability Analysis', fontsize=16, fontweight='bold')\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 9. Overall System Suitability Evaluation Section Analysis",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Create comprehensive analysis summary report\nprint(\"=\" * 80)\nprint(\"JCC2 USER QUESTIONNAIRE COMPREHENSIVE ANALYSIS COMPLETE\")\nprint(\"=\" * 80)\nprint(f\"\\nData Source: {csv_file}\")\nprint(f\"Total Responses Analyzed: {len(df)}\")\nprint(f\"Date Range: {df['user_information.date'].min()} to {df['user_information.date'].max()}\")\n\n# Count all sections analyzed\nall_sections = list(processor.sections.keys())\nprint(f\"\\nTotal Sections Analyzed: {len(all_sections)}\")\nprint(f\"Total Fields Analyzed: {sum(len(fields) for fields in processor.sections.values())}\")\n\n# List major section categories\nprint(\"\\nMajor Section Categories Analyzed:\")\nprint(\"  ✓ Demographics & Roles\")\nprint(\"    - User Information\")\nprint(\"    - Role and Echelon\")\nprint(\"  ✓ Experience & Usage\")\nprint(\"    - Operational JCC2 Experience\")\nprint(\"    - JCC2 Application Usage\")\nprint(\"  ✓ Performance Measures (MOPs)\")\nmop_sections = [s for s in all_sections if s.startswith('mop')]\nprint(f\"    - {len(mop_sections)} MOP sections analyzed\")\nprint(\"  ✓ Suitability Measures (MOSs)\")\nmos_sections = [s for s in all_sections if s.startswith('mos')]\nprint(f\"    - {len(mos_sections)} MOS sections analyzed\")\nprint(\"  ✓ System Evaluation\")\nprint(\"    - Reporting and Data Export\")\nprint(\"    - Overall System Usability (SUS)\")\nprint(\"    - Overall System Suitability Evaluation\")\n\nprint(\"\\nKey Metrics Calculated:\")\nif sus_scores:\n    print(f\"  • Average SUS Score: {np.mean(sus_scores):.1f}\")\nif 'nps_score' in locals():\n    print(f\"  • Net Promoter Score: {nps_score:.1f}\")\nprint(f\"  • Average Field Completion: {df.notna().sum().sum() / (len(df) * len(df.columns)) * 100:.1f}%\")\n\nprint(\"\\nVisualization Types Created:\")\nprint(\"  • Bar charts, pie charts, and histograms\")\nprint(\"  • Heatmaps and correlation matrices\")\nprint(\"  • Time series and trend analyses\")\nprint(\"  • Scatter plots and cross-tabulations\")\nprint(\"  • Word frequency analyses\")\nprint(\"  • Distribution comparisons\")\nprint(\"  • Comprehensive summary dashboards\")\n\nprint(\"\\nAnalysis Highlights:\")\nprint(\"  • Full coverage of all questionnaire sections\")\nprint(\"  • Application-specific effectiveness and suitability ratings\")\nprint(\"  • User experience and training correlations\")\nprint(\"  • System usability and recommendation metrics\")\nprint(\"  • Temporal trends and response patterns\")\nprint(\"  • Cross-sectional quality assessments\")\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"Analysis notebook ready for insights extraction and decision-making.\")\nprint(\"=\" * 80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary dashboard combining key insights from all sections\n",
    "fig = plt.figure(figsize=(20, 16))\n",
    "\n",
    "# 1. Section completion overview\n",
    "ax1 = plt.subplot(3, 3, 1)\n",
    "section_completion = {}\n",
    "for section in sections_to_analyze:\n",
    "    if section in processor.sections:\n",
    "        fields = processor.sections[section]\n",
    "        completion_rates = [df[field].notna().mean() for field in fields if field in df.columns]\n",
    "        section_completion[section] = np.mean(completion_rates) if completion_rates else 0\n",
    "\n",
    "comp_series = pd.Series(section_completion)\n",
    "comp_series.plot(kind='bar', ax=ax1, color=COLORS['primary'])\n",
    "ax1.set_title('Average Completion Rate by Section', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Section')\n",
    "ax1.set_ylabel('Completion Rate')\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "for i, (section, rate) in enumerate(comp_series.items()):\n",
    "    ax1.text(i, rate + 0.02, f'{rate:.1%}', ha='center', fontweight='bold')\n",
    "\n",
    "# 2. Cyber operator distribution by experience\n",
    "ax2 = plt.subplot(3, 3, 2)\n",
    "if 'role_and_echelon.is_cyber_operator' in df.columns and 'operational_jcc2_experience.exp_cyberoperations' in df.columns:\n",
    "    cyber_exp_cross = pd.crosstab(df['role_and_echelon.is_cyber_operator'],\n",
    "                                  df['operational_jcc2_experience.exp_cyberoperations'])\n",
    "    cyber_exp_cross.T.plot(kind='bar', ax=ax2, color=[COLORS['success'], COLORS['warning']])\n",
    "    ax2.set_title('Cyber Operations Experience by Operator Status', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('Experience Level')\n",
    "    ax2.set_ylabel('Count')\n",
    "    ax2.legend(title='Is Cyber Operator')\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 3. Top applications by usage and effectiveness\n",
    "ax3 = plt.subplot(3, 3, 3)\n",
    "# Combine adoption rate and effectiveness\n",
    "app_scores = {}\n",
    "for app in ['a2it', 'cad', 'codex', 'crucible', 'cyber9line', 'dispatch', \n",
    "            'jcc2cyberops', 'jcc2readiness', 'madss', 'rally', 'redmap', \n",
    "            'sigact', 'threathub', 'triage', 'unity']:\n",
    "    # Check experience field\n",
    "    exp_field = f'operational_jcc2_experience.exp_app_{app}'\n",
    "    intel_field = f'mop_1_1_1.intelligence_data_provided_{app}'\n",
    "    \n",
    "    adoption = 0\n",
    "    effectiveness = 0\n",
    "    \n",
    "    if exp_field in df.columns:\n",
    "        exp_counts = df[exp_field].value_counts()\n",
    "        total = exp_counts.sum()\n",
    "        na_count = exp_counts.get('NA', 0)\n",
    "        if total > 0:\n",
    "            adoption = (total - na_count) / total\n",
    "    \n",
    "    if intel_field in df.columns:\n",
    "        ratings = df[intel_field].dropna()\n",
    "        if len(ratings) > 0:\n",
    "            numeric_ratings = ratings.map(effectiveness_map).fillna(0)\n",
    "            effectiveness = numeric_ratings[numeric_ratings > 0].mean() / 6 if len(numeric_ratings[numeric_ratings > 0]) > 0 else 0\n",
    "    \n",
    "    if adoption > 0 or effectiveness > 0:\n",
    "        app_scores[app.upper()] = (adoption + effectiveness) / 2\n",
    "\n",
    "if app_scores:\n",
    "    top_apps = pd.Series(app_scores).sort_values(ascending=False).head(10)\n",
    "    top_apps.plot(kind='bar', ax=ax3, color=COLORS['tertiary'])\n",
    "    ax3.set_title('Top 10 Applications (Combined Score)', fontsize=14, fontweight='bold')\n",
    "    ax3.set_xlabel('Application')\n",
    "    ax3.set_ylabel('Combined Score (0-1)')\n",
    "    ax3.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 4. Response distribution over time\n",
    "ax4 = plt.subplot(3, 3, 4)\n",
    "if 'user_information.date' in df.columns:\n",
    "    df['month_year'] = pd.to_datetime(df['user_information.date']).dt.to_period('M')\n",
    "    monthly_counts = df['month_year'].value_counts().sort_index()\n",
    "    monthly_counts.index = monthly_counts.index.to_timestamp()\n",
    "    monthly_counts.plot(kind='line', ax=ax4, color=COLORS['secondary'], marker='o', linewidth=2)\n",
    "    ax4.set_title('Response Trend Over Time', fontsize=14, fontweight='bold')\n",
    "    ax4.set_xlabel('Month')\n",
    "    ax4.set_ylabel('Number of Responses')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Experience level distribution summary\n",
    "ax5 = plt.subplot(3, 3, 5)\n",
    "exp_summary = {'< 1 Year': 0, '1-3 Years': 0, '3-5 Years': 0, '> 5 Years': 0}\n",
    "exp_fields = [col for col in df.columns if 'operational_jcc2_experience.exp_app_' in col]\n",
    "for field in exp_fields:\n",
    "    counts = df[field].value_counts()\n",
    "    for exp_level in exp_summary:\n",
    "        exp_summary[exp_level] += counts.get(exp_level, 0)\n",
    "\n",
    "exp_series = pd.Series(exp_summary)\n",
    "exp_series.plot(kind='pie', ax=ax5, autopct='%1.1f%%', startangle=90, \n",
    "                colors=[COLORS['info'], COLORS['primary'], COLORS['tertiary'], COLORS['success']])\n",
    "ax5.set_title('Overall Experience Distribution', fontsize=14, fontweight='bold')\n",
    "ax5.set_ylabel('')\n",
    "\n",
    "# 6. Key metrics summary\n",
    "ax6 = plt.subplot(3, 3, 6)\n",
    "ax6.axis('off')\n",
    "metrics_text = f\"\"\"\n",
    "Key Metrics Summary:\n",
    "\n",
    "Total Responses: {len(df)}\n",
    "Unique Events: {df['user_information.event'].nunique()}\n",
    "Unique Units: {df['user_information.unit'].nunique()}\n",
    "Cyber Operators: {(df['role_and_echelon.is_cyber_operator'] == 'Yes').sum()}\n",
    "Average Fields Completed: {df.notna().sum(axis=1).mean():.0f}\n",
    "Most Used Application: {top_apps.index[0] if len(top_apps) > 0 else 'N/A'}\n",
    "\"\"\"\n",
    "ax6.text(0.1, 0.5, metrics_text, transform=ax6.transAxes, fontsize=12, \n",
    "         verticalalignment='center', fontfamily='monospace',\n",
    "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "# 7. Data quality heatmap\n",
    "ax7 = plt.subplot(3, 3, (7, 9))  # Span bottom row\n",
    "quality_matrix = []\n",
    "section_names = []\n",
    "for section in sections_to_analyze:\n",
    "    if section in processor.sections:\n",
    "        section_names.append(section.replace('_', ' ').title())\n",
    "        fields = processor.sections[section]\n",
    "        row = []\n",
    "        for field in fields[:10]:  # First 10 fields for readability\n",
    "            if field in df.columns:\n",
    "                row.append(df[field].notna().mean())\n",
    "        quality_matrix.append(row)\n",
    "\n",
    "if quality_matrix:\n",
    "    quality_df = pd.DataFrame(quality_matrix, index=section_names)\n",
    "    sns.heatmap(quality_df, annot=True, fmt='.2f', cmap='RdYlGn', ax=ax7, \n",
    "                cbar_kws={'label': 'Completion Rate'}, vmin=0, vmax=1)\n",
    "    ax7.set_title('Data Quality Heatmap by Section', fontsize=14, fontweight='bold')\n",
    "    ax7.set_xlabel('Field Index')\n",
    "    ax7.set_ylabel('Section')\n",
    "\n",
    "plt.suptitle('JCC2 User Questionnaire - Executive Summary Dashboard', fontsize=18, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save all visualizations\n",
    "def save_all_visualizations():\n",
    "    \"\"\"\n",
    "    Re-run all visualizations and save them as high-quality images\n",
    "    \"\"\"\n",
    "    import os\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = 'jcc2_visualizations'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"Saving visualizations to {output_dir}/...\")\n",
    "    \n",
    "    # Note: In a real implementation, you would re-run each visualization\n",
    "    # and save it using plt.savefig(). Here's an example structure:\n",
    "    \n",
    "    sections = [\n",
    "        'user_information_analysis',\n",
    "        'role_echelon_analysis', \n",
    "        'operational_experience_analysis',\n",
    "        'mop_111_intelligence_analysis',\n",
    "        'executive_summary_dashboard'\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nTo save visualizations, re-run each section's code and add:\")\n",
    "    print(\"plt.savefig(f'{output_dir}/section_name.png', dpi=300, bbox_inches='tight')\")\n",
    "    print(\"\\nVisualization sections ready for export:\")\n",
    "    for section in sections:\n",
    "        print(f\"  - {section}\")\n",
    "\n",
    "# Call the function\n",
    "save_all_visualizations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create analysis summary report\n",
    "print(\"=\" * 80)\n",
    "print(\"JCC2 USER QUESTIONNAIRE ANALYSIS COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nData Source: {csv_file}\")\n",
    "print(f\"Total Responses Analyzed: {len(df)}\")\n",
    "print(f\"Date Range: {df['user_information.date'].min()} to {df['user_information.date'].max()}\")\n",
    "print(f\"\\nSections Analyzed:\")\n",
    "for section in sections_to_analyze:\n",
    "    if section in processor.sections:\n",
    "        print(f\"  ✓ {section}: {len(processor.sections[section])} fields\")\n",
    "print(\"\\nKey Insights Generated:\")\n",
    "print(\"  • User demographics and participation patterns\")\n",
    "print(\"  • Role distribution and cyber operator analysis\")\n",
    "print(\"  • Application experience levels and adoption rates\")\n",
    "print(\"  • Intelligence data effectiveness ratings\")\n",
    "print(\"  • Cross-sectional quality and completion metrics\")\n",
    "print(\"\\nVisualization Types Created:\")\n",
    "print(\"  • Bar charts, pie charts, and histograms\")\n",
    "print(\"  • Heatmaps and correlation matrices\")\n",
    "print(\"  • Time series and trend analyses\")\n",
    "print(\"  • Scatter plots and cross-tabulations\")\n",
    "print(\"  • Executive summary dashboard\")\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}