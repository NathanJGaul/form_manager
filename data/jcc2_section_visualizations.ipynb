{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JCC2 Section-Specific Visualizations\n",
    "\n",
    "This notebook provides comprehensive visualizations for key sections of the JCC2 User Questionnaire:\n",
    "- User Information\n",
    "- Role and Echelon\n",
    "- Operational JCC2 Experience\n",
    "- MOP 1.1.1 (Intelligence Data)\n",
    "\n",
    "Each section includes tailored visualizations based on the data types and patterns found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import JCC2 processor\n",
    "from jcc2_data_processor import create_processor, DataFormat\n",
    "\n",
    "# Set up visualization style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"Set2\")\n",
    "\n",
    "# Configure display options\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Color palette for consistent styling\n",
    "COLORS = {\n",
    "    'primary': '#2E86AB',\n",
    "    'secondary': '#A23B72',\n",
    "    'tertiary': '#F18F01',\n",
    "    'quaternary': '#C73E1D',\n",
    "    'success': '#52B788',\n",
    "    'warning': '#F77F00',\n",
    "    'info': '#5C946E'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "csv_file = \"mock_20_jcc2_user_questionnaire.csv\"\n",
    "processor = create_processor(csv_file)\n",
    "df = processor.load_data()\n",
    "\n",
    "print(f\"Loaded {len(df)} responses\")\n",
    "print(f\"Data format: {processor.format_type.value}\")\n",
    "print(f\"\\nSections to analyze:\")\n",
    "sections_to_analyze = ['user_information', 'role_and_echelon', 'operational_jcc2_experience', 'mop_1_1_1']\n",
    "for section in sections_to_analyze:\n",
    "    if section in processor.sections:\n",
    "        print(f\"  - {section}: {len(processor.sections[section])} fields\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. User Information Section Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze user_information section\n",
    "user_info_summary = processor.get_section_summary('user_information')\n",
    "print(\"User Information Fields:\")\n",
    "for field, data in user_info_summary['field_summaries'].items():\n",
    "    print(f\"  - {field}: {data['field_type']} (completion: {data['completion_rate']:.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User Information Visualizations\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "\n",
    "# 1. Event participation distribution\n",
    "ax1 = plt.subplot(2, 3, 1)\n",
    "event_data = df['user_information.event'].value_counts()\n",
    "event_data.plot(kind='bar', ax=ax1, color=COLORS['primary'])\n",
    "ax1.set_title('Distribution of Events', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Event Name')\n",
    "ax1.set_ylabel('Number of Participants')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 2. Participation timeline\n",
    "ax2 = plt.subplot(2, 3, 2)\n",
    "df['user_information.date'] = pd.to_datetime(df['user_information.date'])\n",
    "date_counts = df['user_information.date'].value_counts().sort_index()\n",
    "date_counts.plot(kind='line', ax=ax2, color=COLORS['secondary'], marker='o')\n",
    "ax2.set_title('Participation Timeline', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Date')\n",
    "ax2.set_ylabel('Number of Responses')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 3. Unit distribution (top 10)\n",
    "ax3 = plt.subplot(2, 3, 3)\n",
    "unit_data = df['user_information.unit'].value_counts().head(10)\n",
    "unit_data.plot(kind='barh', ax=ax3, color=COLORS['tertiary'])\n",
    "ax3.set_title('Top 10 Units by Participation', fontsize=14, fontweight='bold')\n",
    "ax3.set_xlabel('Number of Participants')\n",
    "ax3.set_ylabel('Unit')\n",
    "\n",
    "# 4. Rank distribution word cloud style (simplified as bar chart)\n",
    "ax4 = plt.subplot(2, 3, 4)\n",
    "rank_data = df['user_information.rank_name'].value_counts().head(15)\n",
    "rank_data.plot(kind='pie', ax=ax4, autopct='%1.1f%%', startangle=90)\n",
    "ax4.set_title('Rank Distribution', fontsize=14, fontweight='bold')\n",
    "ax4.set_ylabel('')\n",
    "\n",
    "# 5. Contact information completion rates\n",
    "ax5 = plt.subplot(2, 3, 5)\n",
    "contact_fields = ['user_information.email', 'user_information.phone']\n",
    "completion_rates = [df[field].notna().mean() for field in contact_fields]\n",
    "ax5.bar(['Email', 'Phone'], completion_rates, color=[COLORS['success'], COLORS['info']])\n",
    "ax5.set_title('Contact Information Completion Rates', fontsize=14, fontweight='bold')\n",
    "ax5.set_ylabel('Completion Rate')\n",
    "ax5.set_ylim(0, 1)\n",
    "for i, v in enumerate(completion_rates):\n",
    "    ax5.text(i, v + 0.02, f'{v:.1%}', ha='center', fontweight='bold')\n",
    "\n",
    "# 6. Data quality summary\n",
    "ax6 = plt.subplot(2, 3, 6)\n",
    "quality_data = {\n",
    "    'Complete Records': (df[['user_information.event', 'user_information.date', \n",
    "                            'user_information.rank_name', 'user_information.unit']].notna().all(axis=1)).sum(),\n",
    "    'Partial Records': len(df) - (df[['user_information.event', 'user_information.date', \n",
    "                                      'user_information.rank_name', 'user_information.unit']].notna().all(axis=1)).sum()\n",
    "}\n",
    "ax6.pie(quality_data.values(), labels=quality_data.keys(), autopct='%1.1f%%', \n",
    "        colors=[COLORS['success'], COLORS['warning']], startangle=90)\n",
    "ax6.set_title('Data Completeness', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.suptitle('User Information Section Analysis', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Role and Echelon Section Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze role_and_echelon section\n",
    "role_summary = processor.get_section_summary('role_and_echelon')\n",
    "print(\"Role and Echelon Fields:\")\n",
    "for field, data in role_summary['field_summaries'].items():\n",
    "    print(f\"  - {field}: {data['field_type']} (completion: {data['completion_rate']:.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Role and Echelon Visualizations\n",
    "fig = plt.figure(figsize=(20, 15))\n",
    "\n",
    "# 1. Current role status distribution\n",
    "ax1 = plt.subplot(3, 3, 1)\n",
    "role_status = df['role_and_echelon.current_role_status'].value_counts()\n",
    "colors = [COLORS['primary'], COLORS['secondary'], COLORS['tertiary'], COLORS['quaternary']][:len(role_status)]\n",
    "role_status.plot(kind='pie', ax=ax1, autopct='%1.1f%%', colors=colors, startangle=45)\n",
    "ax1.set_title('Current Role Status Distribution', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylabel('')\n",
    "\n",
    "# 2. Cyber operator distribution\n",
    "ax2 = plt.subplot(3, 3, 2)\n",
    "cyber_op = df['role_and_echelon.is_cyber_operator'].value_counts()\n",
    "cyber_op.plot(kind='bar', ax=ax2, color=[COLORS['success'], COLORS['warning']])\n",
    "ax2.set_title('Cyber Operator Distribution', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Is Cyber Operator')\n",
    "ax2.set_ylabel('Count')\n",
    "ax2.tick_params(axis='x', rotation=0)\n",
    "for i, v in enumerate(cyber_op.values):\n",
    "    ax2.text(i, v + 0.5, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "# 3. Echelon distribution (for cyber operators)\n",
    "ax3 = plt.subplot(3, 3, 3)\n",
    "cyber_ops_df = df[df['role_and_echelon.is_cyber_operator'] == 'Yes']\n",
    "if not cyber_ops_df.empty and 'role_and_echelon.echelon' in cyber_ops_df.columns:\n",
    "    # Parse echelon data (assuming it's a multi-select field)\n",
    "    echelon_counts = {}\n",
    "    for echelons in cyber_ops_df['role_and_echelon.echelon'].dropna():\n",
    "        if isinstance(echelons, list):\n",
    "            for echelon in echelons:\n",
    "                echelon_counts[echelon] = echelon_counts.get(echelon, 0) + 1\n",
    "        else:\n",
    "            # Handle if it's stored as string\n",
    "            for echelon in str(echelons).split('; '):\n",
    "                if echelon:\n",
    "                    echelon_counts[echelon] = echelon_counts.get(echelon, 0) + 1\n",
    "    \n",
    "    if echelon_counts:\n",
    "        echelon_df = pd.Series(echelon_counts).sort_values(ascending=True)\n",
    "        echelon_df.plot(kind='barh', ax=ax3, color=COLORS['info'])\n",
    "        ax3.set_title('Echelon Levels (Cyber Operators)', fontsize=14, fontweight='bold')\n",
    "        ax3.set_xlabel('Count')\n",
    "else:\n",
    "    ax3.text(0.5, 0.5, 'No cyber operator echelon data', ha='center', va='center', transform=ax3.transAxes)\n",
    "    ax3.set_title('Echelon Levels (Cyber Operators)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 4. Duties distribution (multi-select analysis)\n",
    "ax4 = plt.subplot(3, 3, 4)\n",
    "duties_counts = {}\n",
    "for duties in df['role_and_echelon.duties'].dropna():\n",
    "    if isinstance(duties, list):\n",
    "        for duty in duties:\n",
    "            duties_counts[duty] = duties_counts.get(duty, 0) + 1\n",
    "    else:\n",
    "        # Handle if it's stored as string\n",
    "        for duty in str(duties).split('; '):\n",
    "            if duty:\n",
    "                duties_counts[duty] = duties_counts.get(duty, 0) + 1\n",
    "\n",
    "if duties_counts:\n",
    "    duties_df = pd.Series(duties_counts).sort_values(ascending=False)\n",
    "    duties_df.plot(kind='bar', ax=ax4, color=COLORS['primary'])\n",
    "    ax4.set_title('Primary Duties Distribution', fontsize=14, fontweight='bold')\n",
    "    ax4.set_xlabel('Duty Type')\n",
    "    ax4.set_ylabel('Count')\n",
    "    ax4.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 5. Cyber division/team distribution\n",
    "ax5 = plt.subplot(3, 3, 5)\n",
    "if 'role_and_echelon.cyber_ops_division_team' in df.columns:\n",
    "    cyber_teams = df['role_and_echelon.cyber_ops_division_team'].dropna().value_counts().head(10)\n",
    "    if not cyber_teams.empty:\n",
    "        cyber_teams.plot(kind='barh', ax=ax5, color=COLORS['secondary'])\n",
    "        ax5.set_title('Top 10 Cyber Ops Divisions/Teams', fontsize=14, fontweight='bold')\n",
    "        ax5.set_xlabel('Count')\n",
    "    else:\n",
    "        ax5.text(0.5, 0.5, 'No cyber team data available', ha='center', va='center', transform=ax5.transAxes)\n",
    "\n",
    "# 6. Role status by cyber operator status\n",
    "ax6 = plt.subplot(3, 3, 6)\n",
    "role_cyber_cross = pd.crosstab(df['role_and_echelon.current_role_status'], \n",
    "                               df['role_and_echelon.is_cyber_operator'])\n",
    "role_cyber_cross.plot(kind='bar', ax=ax6, color=[COLORS['success'], COLORS['warning']])\n",
    "ax6.set_title('Role Status by Cyber Operator Status', fontsize=14, fontweight='bold')\n",
    "ax6.set_xlabel('Current Role Status')\n",
    "ax6.set_ylabel('Count')\n",
    "ax6.legend(title='Is Cyber Operator')\n",
    "ax6.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 7. Duty combinations heatmap\n",
    "ax7 = plt.subplot(3, 3, 7)\n",
    "# Create a co-occurrence matrix for duties\n",
    "duty_combinations = []\n",
    "for duties in df['role_and_echelon.duties'].dropna():\n",
    "    if isinstance(duties, list):\n",
    "        duty_combinations.append(duties)\n",
    "    else:\n",
    "        duty_combinations.append(str(duties).split('; '))\n",
    "\n",
    "# Count co-occurrences\n",
    "unique_duties = list(duties_counts.keys()) if duties_counts else []\n",
    "co_matrix = pd.DataFrame(0, index=unique_duties[:6], columns=unique_duties[:6])  # Top 6 for readability\n",
    "\n",
    "for combo in duty_combinations:\n",
    "    for i, duty1 in enumerate(combo):\n",
    "        for duty2 in combo[i:]:\n",
    "            if duty1 in co_matrix.index and duty2 in co_matrix.columns:\n",
    "                co_matrix.loc[duty1, duty2] += 1\n",
    "                if duty1 != duty2:\n",
    "                    co_matrix.loc[duty2, duty1] += 1\n",
    "\n",
    "if not co_matrix.empty:\n",
    "    sns.heatmap(co_matrix, annot=True, fmt='d', cmap='YlOrRd', ax=ax7, cbar_kws={'label': 'Co-occurrence Count'})\n",
    "    ax7.set_title('Duty Combinations Heatmap', fontsize=14, fontweight='bold')\n",
    "    ax7.tick_params(axis='x', rotation=45)\n",
    "    ax7.tick_params(axis='y', rotation=0)\n",
    "\n",
    "# 8. Other duties word frequency (simplified)\n",
    "ax8 = plt.subplot(3, 3, 8)\n",
    "other_duties = df['role_and_echelon.other_duties'].dropna()\n",
    "if not other_duties.empty:\n",
    "    # Simple word frequency analysis\n",
    "    all_words = ' '.join(other_duties.astype(str)).lower().split()\n",
    "    word_freq = pd.Series(all_words).value_counts().head(20)\n",
    "    word_freq.plot(kind='barh', ax=ax8, color=COLORS['info'])\n",
    "    ax8.set_title('Top 20 Words in \"Other Duties\"', fontsize=14, fontweight='bold')\n",
    "    ax8.set_xlabel('Frequency')\n",
    "else:\n",
    "    ax8.text(0.5, 0.5, 'No \"other duties\" data', ha='center', va='center', transform=ax8.transAxes)\n",
    "\n",
    "# 9. Completeness by field\n",
    "ax9 = plt.subplot(3, 3, 9)\n",
    "role_fields = [col for col in df.columns if col.startswith('role_and_echelon.')]\n",
    "completeness = [(col.split('.')[-1], df[col].notna().mean()) for col in role_fields]\n",
    "completeness_df = pd.DataFrame(completeness, columns=['Field', 'Completion Rate']).sort_values('Completion Rate')\n",
    "completeness_df.plot(x='Field', y='Completion Rate', kind='barh', ax=ax9, color=COLORS['primary'], legend=False)\n",
    "ax9.set_title('Field Completion Rates', fontsize=14, fontweight='bold')\n",
    "ax9.set_xlabel('Completion Rate')\n",
    "ax9.set_xlim(0, 1)\n",
    "for i, (field, rate) in enumerate(completeness_df.values):\n",
    "    ax9.text(rate + 0.02, i, f'{rate:.1%}', va='center', fontsize=9)\n",
    "\n",
    "plt.suptitle('Role and Echelon Section Analysis', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Operational JCC2 Experience Section Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze operational_jcc2_experience section\n",
    "ops_summary = processor.get_section_summary('operational_jcc2_experience')\n",
    "print(\"Operational JCC2 Experience Fields:\")\n",
    "experience_fields = {}\n",
    "for field, data in ops_summary['field_summaries'].items():\n",
    "    field_name = field.split('.')[-1]\n",
    "    if field_name.startswith('exp_'):\n",
    "        experience_fields[field_name] = data\n",
    "        print(f\"  - {field_name}: {data['field_type']} (completion: {data['completion_rate']:.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operational JCC2 Experience Visualizations\n",
    "fig = plt.figure(figsize=(24, 20))\n",
    "\n",
    "# Extract experience levels for all applications\n",
    "app_experience = {}\n",
    "experience_mapping = {\n",
    "    'exp_cyberoperations': 'Cyber Operations',\n",
    "    'exp_yourcurrentrole': 'Current Role',\n",
    "    'exp_jcc2experience': 'JCC2 Experience',\n",
    "    'exp_app_a2it': 'A2IT',\n",
    "    'exp_app_cad': 'CAD',\n",
    "    'exp_app_codex': 'Codex',\n",
    "    'exp_app_crucible': 'Crucible',\n",
    "    'exp_app_cyber9line': 'Cyber 9-Line',\n",
    "    'exp_app_dispatch': 'Dispatch',\n",
    "    'exp_app_jcc2cyberops': 'JCC2 Cyber-Ops',\n",
    "    'exp_app_jcc2readiness': 'JCC2 Readiness',\n",
    "    'exp_app_madss': 'MADSS',\n",
    "    'exp_app_rally': 'Rally',\n",
    "    'exp_app_redmap': 'REDMAP',\n",
    "    'exp_app_sigact': 'SigAct',\n",
    "    'exp_app_threathub': 'Threat Hub',\n",
    "    'exp_app_triage': 'Triage',\n",
    "    'exp_app_unity': 'Unity'\n",
    "}\n",
    "\n",
    "# 1. Overall experience distribution (first 3 fields)\n",
    "ax1 = plt.subplot(4, 3, 1)\n",
    "overall_exp_fields = ['exp_cyberoperations', 'exp_yourcurrentrole', 'exp_jcc2experience']\n",
    "for i, field in enumerate(overall_exp_fields):\n",
    "    if f'operational_jcc2_experience.{field}' in df.columns:\n",
    "        exp_data = df[f'operational_jcc2_experience.{field}'].value_counts()\n",
    "        exp_data.plot(kind='bar', ax=ax1, alpha=0.7, label=experience_mapping.get(field, field))\n",
    "ax1.set_title('Overall Experience Levels', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Experience Level')\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.legend()\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 2. Application experience heatmap\n",
    "ax2 = plt.subplot(4, 3, (2, 6))  # Span multiple cells\n",
    "app_exp_data = []\n",
    "exp_order = ['< 1 Year', '1-3 Years', '3-5 Years', '> 5 Years', 'NA']\n",
    "for field, label in experience_mapping.items():\n",
    "    if field.startswith('exp_app_') and f'operational_jcc2_experience.{field}' in df.columns:\n",
    "        counts = df[f'operational_jcc2_experience.{field}'].value_counts()\n",
    "        row_data = [counts.get(exp, 0) for exp in exp_order]\n",
    "        app_exp_data.append(row_data)\n",
    "\n",
    "if app_exp_data:\n",
    "    app_labels = [v for k, v in experience_mapping.items() if k.startswith('exp_app_')]\n",
    "    exp_matrix = pd.DataFrame(app_exp_data, index=app_labels[:len(app_exp_data)], columns=exp_order)\n",
    "    sns.heatmap(exp_matrix, annot=True, fmt='d', cmap='YlOrRd', ax=ax2, cbar_kws={'label': 'Number of Users'})\n",
    "    ax2.set_title('Application Experience Heatmap', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('Experience Level')\n",
    "    ax2.set_ylabel('Application')\n",
    "\n",
    "# 3. Experience distribution by application (stacked bar)\n",
    "ax3 = plt.subplot(4, 3, (7, 9))  # Span multiple cells\n",
    "if app_exp_data:\n",
    "    exp_matrix_pct = exp_matrix.div(exp_matrix.sum(axis=1), axis=0) * 100\n",
    "    exp_matrix_pct.plot(kind='barh', stacked=True, ax=ax3, colormap='viridis')\n",
    "    ax3.set_title('Experience Distribution by Application (%)', fontsize=14, fontweight='bold')\n",
    "    ax3.set_xlabel('Percentage')\n",
    "    ax3.set_ylabel('Application')\n",
    "    ax3.legend(title='Experience', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# 4. Applications with most experienced users\n",
    "ax4 = plt.subplot(4, 3, 10)\n",
    "experienced_users = {}\n",
    "for field, label in experience_mapping.items():\n",
    "    if field.startswith('exp_app_') and f'operational_jcc2_experience.{field}' in df.columns:\n",
    "        exp_counts = df[f'operational_jcc2_experience.{field}'].value_counts()\n",
    "        experienced = exp_counts.get('> 5 Years', 0) + exp_counts.get('3-5 Years', 0)\n",
    "        experienced_users[label] = experienced\n",
    "\n",
    "if experienced_users:\n",
    "    exp_series = pd.Series(experienced_users).sort_values(ascending=False).head(10)\n",
    "    exp_series.plot(kind='bar', ax=ax4, color=COLORS['success'])\n",
    "    ax4.set_title('Applications with Most Experienced Users (3+ Years)', fontsize=14, fontweight='bold')\n",
    "    ax4.set_xlabel('Application')\n",
    "    ax4.set_ylabel('Number of Experienced Users')\n",
    "    ax4.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 5. New user distribution (< 1 Year)\n",
    "ax5 = plt.subplot(4, 3, 11)\n",
    "new_users = {}\n",
    "for field, label in experience_mapping.items():\n",
    "    if field.startswith('exp_app_') and f'operational_jcc2_experience.{field}' in df.columns:\n",
    "        exp_counts = df[f'operational_jcc2_experience.{field}'].value_counts()\n",
    "        new = exp_counts.get('< 1 Year', 0)\n",
    "        new_users[label] = new\n",
    "\n",
    "if new_users:\n",
    "    new_series = pd.Series(new_users).sort_values(ascending=False).head(10)\n",
    "    new_series.plot(kind='bar', ax=ax5, color=COLORS['info'])\n",
    "    ax5.set_title('Applications with Most New Users (< 1 Year)', fontsize=14, fontweight='bold')\n",
    "    ax5.set_xlabel('Application')\n",
    "    ax5.set_ylabel('Number of New Users')\n",
    "    ax5.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 6. Application adoption rate (users with any experience vs NA)\n",
    "ax6 = plt.subplot(4, 3, 12)\n",
    "adoption_rates = {}\n",
    "for field, label in experience_mapping.items():\n",
    "    if field.startswith('exp_app_') and f'operational_jcc2_experience.{field}' in df.columns:\n",
    "        exp_counts = df[f'operational_jcc2_experience.{field}'].value_counts()\n",
    "        total_responses = exp_counts.sum()\n",
    "        na_count = exp_counts.get('NA', 0)\n",
    "        if total_responses > 0:\n",
    "            adoption_rate = (total_responses - na_count) / total_responses * 100\n",
    "            adoption_rates[label] = adoption_rate\n",
    "\n",
    "if adoption_rates:\n",
    "    adoption_series = pd.Series(adoption_rates).sort_values(ascending=True)\n",
    "    adoption_series.plot(kind='barh', ax=ax6, color=COLORS['primary'])\n",
    "    ax6.set_title('Application Adoption Rates', fontsize=14, fontweight='bold')\n",
    "    ax6.set_xlabel('Adoption Rate (%)')\n",
    "    ax6.set_ylabel('Application')\n",
    "    ax6.set_xlim(0, 100)\n",
    "    for i, (app, rate) in enumerate(adoption_series.items()):\n",
    "        ax6.text(rate + 1, i, f'{rate:.1f}%', va='center', fontsize=9)\n",
    "\n",
    "plt.suptitle('Operational JCC2 Experience Analysis', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional analysis: Experience correlation matrix\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "# Create numeric mapping for experience levels\n",
    "exp_numeric_map = {\n",
    "    '< 1 Year': 1,\n",
    "    '1-3 Years': 2,\n",
    "    '3-5 Years': 3,\n",
    "    '> 5 Years': 4,\n",
    "    'NA': 0\n",
    "}\n",
    "\n",
    "# Convert experience columns to numeric\n",
    "exp_columns = []\n",
    "exp_labels = []\n",
    "for field, label in experience_mapping.items():\n",
    "    if field.startswith('exp_app_') and f'operational_jcc2_experience.{field}' in df.columns:\n",
    "        col_name = f'operational_jcc2_experience.{field}'\n",
    "        df[f'{col_name}_numeric'] = df[col_name].map(exp_numeric_map).fillna(0)\n",
    "        exp_columns.append(f'{col_name}_numeric')\n",
    "        exp_labels.append(label)\n",
    "\n",
    "if exp_columns:\n",
    "    # Calculate correlation matrix\n",
    "    corr_matrix = df[exp_columns].corr()\n",
    "    \n",
    "    # Create mask for upper triangle\n",
    "    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "    \n",
    "    # Plot heatmap\n",
    "    sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "                center=0, square=True, linewidths=1, cbar_kws={\"shrink\": .8},\n",
    "                xticklabels=exp_labels, yticklabels=exp_labels, ax=ax)\n",
    "    ax.set_title('Application Experience Correlation Matrix', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Clean up numeric columns\n",
    "    df.drop(columns=exp_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. MOP 1.1.1 Intelligence Data Section Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze mop_1_1_1 section\n",
    "mop_summary = processor.get_section_summary('mop_1_1_1')\n",
    "print(\"MOP 1.1.1 Intelligence Data Fields:\")\n",
    "intel_fields = {}\n",
    "for field, data in mop_summary['field_summaries'].items():\n",
    "    field_name = field.split('.')[-1]\n",
    "    intel_fields[field_name] = data\n",
    "    print(f\"  - {field_name}: {data['field_type']} (completion: {data['completion_rate']:.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOP 1.1.1 Intelligence Data Visualizations\n",
    "fig = plt.figure(figsize=(24, 20))\n",
    "\n",
    "# Extract application names from field names\n",
    "intel_apps = set()\n",
    "for field in mop_summary['field_summaries'].keys():\n",
    "    parts = field.split('_')\n",
    "    if len(parts) > 3:\n",
    "        app_name = '_'.join(parts[3:]) if parts[2] in ['provided', 'completion'] else parts[-1]\n",
    "        intel_apps.add(app_name)\n",
    "\n",
    "intel_apps = sorted(list(intel_apps))\n",
    "\n",
    "# 1. Intelligence data provision by application\n",
    "ax1 = plt.subplot(4, 3, 1)\n",
    "provided_data = {}\n",
    "for app in intel_apps:\n",
    "    field_name = f'mop_1_1_1.intelligence_data_provided_{app}'\n",
    "    if field_name in df.columns:\n",
    "        counts = df[field_name].value_counts()\n",
    "        provided_data[app] = counts\n",
    "\n",
    "if provided_data:\n",
    "    # Calculate effectiveness scores\n",
    "    effectiveness_map = {\n",
    "        'Completely Ineffective': 1, 'Moderately Ineffective': 2, 'Slightly Ineffective': 3,\n",
    "        'Slightly Effective': 4, 'Moderately Effective': 5, 'Completely Effective': 6,\n",
    "        'Not Applicable': 0\n",
    "    }\n",
    "    \n",
    "    avg_scores = {}\n",
    "    for app, counts in provided_data.items():\n",
    "        total_score = sum(effectiveness_map.get(rating, 0) * count for rating, count in counts.items())\n",
    "        total_responses = sum(count for rating, count in counts.items() if rating != 'Not Applicable')\n",
    "        if total_responses > 0:\n",
    "            avg_scores[app.upper()] = total_score / total_responses\n",
    "    \n",
    "    if avg_scores:\n",
    "        scores_series = pd.Series(avg_scores).sort_values(ascending=True)\n",
    "        scores_series.plot(kind='barh', ax=ax1, color=COLORS['primary'])\n",
    "        ax1.set_title('Average Intelligence Data Provision Effectiveness', fontsize=14, fontweight='bold')\n",
    "        ax1.set_xlabel('Average Effectiveness Score (1-6)')\n",
    "        ax1.set_xlim(0, 6)\n",
    "        for i, (app, score) in enumerate(scores_series.items()):\n",
    "            ax1.text(score + 0.1, i, f'{score:.2f}', va='center', fontsize=9)\n",
    "\n",
    "# 2. Role completion effectiveness by application\n",
    "ax2 = plt.subplot(4, 3, 2)\n",
    "completion_data = {}\n",
    "for app in intel_apps:\n",
    "    field_name = f'mop_1_1_1.intelligence_data_completion_of_role_{app}'\n",
    "    if field_name in df.columns:\n",
    "        counts = df[field_name].value_counts()\n",
    "        completion_data[app] = counts\n",
    "\n",
    "if completion_data:\n",
    "    avg_completion_scores = {}\n",
    "    for app, counts in completion_data.items():\n",
    "        total_score = sum(effectiveness_map.get(rating, 0) * count for rating, count in counts.items())\n",
    "        total_responses = sum(count for rating, count in counts.items() if rating != 'Not Applicable')\n",
    "        if total_responses > 0:\n",
    "            avg_completion_scores[app.upper()] = total_score / total_responses\n",
    "    \n",
    "    if avg_completion_scores:\n",
    "        comp_series = pd.Series(avg_completion_scores).sort_values(ascending=True)\n",
    "        comp_series.plot(kind='barh', ax=ax2, color=COLORS['secondary'])\n",
    "        ax2.set_title('Average Role Completion Support Effectiveness', fontsize=14, fontweight='bold')\n",
    "        ax2.set_xlabel('Average Effectiveness Score (1-6)')\n",
    "        ax2.set_xlim(0, 6)\n",
    "        for i, (app, score) in enumerate(comp_series.items()):\n",
    "            ax2.text(score + 0.1, i, f'{score:.2f}', va='center', fontsize=9)\n",
    "\n",
    "# 3. Overall intelligence effectiveness\n",
    "ax3 = plt.subplot(4, 3, 3)\n",
    "if 'mop_1_1_1.intelligence_data_overall_effectiveness' in df.columns:\n",
    "    overall_counts = df['mop_1_1_1.intelligence_data_overall_effectiveness'].value_counts()\n",
    "    colors_map = {\n",
    "        'Completely Effective': COLORS['success'],\n",
    "        'Moderately Effective': COLORS['info'],\n",
    "        'Slightly Effective': COLORS['primary'],\n",
    "        'Slightly Ineffective': COLORS['tertiary'],\n",
    "        'Moderately Ineffective': COLORS['warning'],\n",
    "        'Completely Ineffective': COLORS['quaternary'],\n",
    "        'Not Applicable': 'gray'\n",
    "    }\n",
    "    colors = [colors_map.get(rating, 'gray') for rating in overall_counts.index]\n",
    "    overall_counts.plot(kind='pie', ax=ax3, autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "    ax3.set_title('Overall Intelligence Data Effectiveness', fontsize=14, fontweight='bold')\n",
    "    ax3.set_ylabel('')\n",
    "\n",
    "# 4. Effectiveness comparison heatmap\n",
    "ax4 = plt.subplot(4, 3, (4, 6))  # Span multiple cells\n",
    "if provided_data and completion_data:\n",
    "    # Create comparison matrix\n",
    "    comparison_data = []\n",
    "    app_labels = []\n",
    "    \n",
    "    for app in intel_apps:\n",
    "        if app in provided_data and app in completion_data:\n",
    "            app_labels.append(app.upper())\n",
    "            row = []\n",
    "            \n",
    "            # Data provision scores\n",
    "            for rating in ['Completely Ineffective', 'Moderately Ineffective', 'Slightly Ineffective',\n",
    "                          'Slightly Effective', 'Moderately Effective', 'Completely Effective']:\n",
    "                row.append(provided_data[app].get(rating, 0))\n",
    "            \n",
    "            comparison_data.append(row)\n",
    "    \n",
    "    if comparison_data:\n",
    "        comp_df = pd.DataFrame(comparison_data, index=app_labels, \n",
    "                              columns=['Completely\\nIneffective', 'Moderately\\nIneffective', 'Slightly\\nIneffective',\n",
    "                                      'Slightly\\nEffective', 'Moderately\\nEffective', 'Completely\\nEffective'])\n",
    "        sns.heatmap(comp_df, annot=True, fmt='d', cmap='RdYlGn', ax=ax4, cbar_kws={'label': 'Response Count'})\n",
    "        ax4.set_title('Intelligence Data Provision Effectiveness Distribution', fontsize=14, fontweight='bold')\n",
    "        ax4.set_xlabel('Effectiveness Rating')\n",
    "        ax4.set_ylabel('Application')\n",
    "\n",
    "# 5. Provision vs Completion scatter plot\n",
    "ax5 = plt.subplot(4, 3, 7)\n",
    "if avg_scores and avg_completion_scores:\n",
    "    scatter_data = []\n",
    "    for app in set(avg_scores.keys()) & set(avg_completion_scores.keys()):\n",
    "        scatter_data.append({\n",
    "            'app': app,\n",
    "            'provision': avg_scores[app],\n",
    "            'completion': avg_completion_scores[app]\n",
    "        })\n",
    "    \n",
    "    if scatter_data:\n",
    "        scatter_df = pd.DataFrame(scatter_data)\n",
    "        ax5.scatter(scatter_df['provision'], scatter_df['completion'], s=100, alpha=0.6, color=COLORS['primary'])\n",
    "        \n",
    "        # Add labels\n",
    "        for _, row in scatter_df.iterrows():\n",
    "            ax5.annotate(row['app'], (row['provision'], row['completion']), \n",
    "                        xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "        \n",
    "        # Add diagonal line\n",
    "        ax5.plot([0, 6], [0, 6], 'k--', alpha=0.3)\n",
    "        \n",
    "        ax5.set_xlabel('Data Provision Effectiveness')\n",
    "        ax5.set_ylabel('Role Completion Effectiveness')\n",
    "        ax5.set_title('Provision vs Completion Effectiveness', fontsize=14, fontweight='bold')\n",
    "        ax5.set_xlim(0, 6)\n",
    "        ax5.set_ylim(0, 6)\n",
    "        ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Response rate by application\n",
    "ax6 = plt.subplot(4, 3, 8)\n",
    "response_rates = {}\n",
    "for app in intel_apps:\n",
    "    field_name = f'mop_1_1_1.intelligence_data_provided_{app}'\n",
    "    if field_name in df.columns:\n",
    "        total = len(df)\n",
    "        non_na = df[field_name].notna().sum()\n",
    "        response_rates[app.upper()] = (non_na / total) * 100\n",
    "\n",
    "if response_rates:\n",
    "    resp_series = pd.Series(response_rates).sort_values(ascending=True)\n",
    "    resp_series.plot(kind='barh', ax=ax6, color=COLORS['info'])\n",
    "    ax6.set_title('Response Rates by Application', fontsize=14, fontweight='bold')\n",
    "    ax6.set_xlabel('Response Rate (%)')\n",
    "    ax6.set_xlim(0, 100)\n",
    "    for i, (app, rate) in enumerate(resp_series.items()):\n",
    "        ax6.text(rate + 1, i, f'{rate:.1f}%', va='center', fontsize=9)\n",
    "\n",
    "# 7. Top and bottom performers\n",
    "ax7 = plt.subplot(4, 3, 9)\n",
    "if avg_scores:\n",
    "    # Combine provision and completion scores\n",
    "    combined_scores = {}\n",
    "    for app in avg_scores:\n",
    "        prov_score = avg_scores.get(app, 0)\n",
    "        comp_score = avg_completion_scores.get(app, 0) if avg_completion_scores else 0\n",
    "        combined_scores[app] = (prov_score + comp_score) / 2 if comp_score else prov_score\n",
    "    \n",
    "    # Get top 5 and bottom 5\n",
    "    sorted_apps = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_bottom = sorted_apps[:5] + sorted_apps[-5:]\n",
    "    \n",
    "    apps = [app for app, _ in top_bottom]\n",
    "    scores = [score for _, score in top_bottom]\n",
    "    colors = [COLORS['success'] if i < 5 else COLORS['quaternary'] for i in range(len(apps))]\n",
    "    \n",
    "    y_pos = np.arange(len(apps))\n",
    "    ax7.barh(y_pos, scores, color=colors)\n",
    "    ax7.set_yticks(y_pos)\n",
    "    ax7.set_yticklabels(apps)\n",
    "    ax7.set_xlabel('Combined Effectiveness Score')\n",
    "    ax7.set_title('Top 5 and Bottom 5 Applications', fontsize=14, fontweight='bold')\n",
    "    ax7.set_xlim(0, 6)\n",
    "    \n",
    "    for i, score in enumerate(scores):\n",
    "        ax7.text(score + 0.1, i, f'{score:.2f}', va='center', fontsize=9)\n",
    "\n",
    "# 8. Effectiveness distribution\n",
    "ax8 = plt.subplot(4, 3, 10)\n",
    "all_ratings = []\n",
    "for app in intel_apps:\n",
    "    field_name = f'mop_1_1_1.intelligence_data_provided_{app}'\n",
    "    if field_name in df.columns:\n",
    "        ratings = df[field_name].dropna()\n",
    "        all_ratings.extend(ratings.tolist())\n",
    "\n",
    "if all_ratings:\n",
    "    rating_counts = pd.Series(all_ratings).value_counts()\n",
    "    rating_order = ['Completely Ineffective', 'Moderately Ineffective', 'Slightly Ineffective',\n",
    "                   'Slightly Effective', 'Moderately Effective', 'Completely Effective', 'Not Applicable']\n",
    "    rating_counts = rating_counts.reindex(rating_order, fill_value=0)\n",
    "    \n",
    "    colors = [colors_map.get(rating, 'gray') for rating in rating_counts.index]\n",
    "    rating_counts.plot(kind='bar', ax=ax8, color=colors)\n",
    "    ax8.set_title('Overall Rating Distribution', fontsize=14, fontweight='bold')\n",
    "    ax8.set_xlabel('Rating')\n",
    "    ax8.set_ylabel('Count')\n",
    "    ax8.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 9. NA rate comparison\n",
    "ax9 = plt.subplot(4, 3, 11)\n",
    "na_rates = {}\n",
    "for app in intel_apps:\n",
    "    field_name = f'mop_1_1_1.intelligence_data_provided_{app}'\n",
    "    if field_name in df.columns:\n",
    "        na_count = (df[field_name] == 'Not Applicable').sum()\n",
    "        total = df[field_name].notna().sum()\n",
    "        if total > 0:\n",
    "            na_rates[app.upper()] = (na_count / total) * 100\n",
    "\n",
    "if na_rates:\n",
    "    na_series = pd.Series(na_rates).sort_values(ascending=False).head(10)\n",
    "    na_series.plot(kind='bar', ax=ax9, color=COLORS['warning'])\n",
    "    ax9.set_title('\"Not Applicable\" Response Rates (Top 10)', fontsize=14, fontweight='bold')\n",
    "    ax9.set_xlabel('Application')\n",
    "    ax9.set_ylabel('NA Rate (%)')\n",
    "    ax9.tick_params(axis='x', rotation=45)\n",
    "    ax9.set_ylim(0, 100)\n",
    "\n",
    "plt.suptitle('MOP 1.1.1 Intelligence Data Analysis', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary dashboard combining key insights from all sections\n",
    "fig = plt.figure(figsize=(20, 16))\n",
    "\n",
    "# 1. Section completion overview\n",
    "ax1 = plt.subplot(3, 3, 1)\n",
    "section_completion = {}\n",
    "for section in sections_to_analyze:\n",
    "    if section in processor.sections:\n",
    "        fields = processor.sections[section]\n",
    "        completion_rates = [df[field].notna().mean() for field in fields if field in df.columns]\n",
    "        section_completion[section] = np.mean(completion_rates) if completion_rates else 0\n",
    "\n",
    "comp_series = pd.Series(section_completion)\n",
    "comp_series.plot(kind='bar', ax=ax1, color=COLORS['primary'])\n",
    "ax1.set_title('Average Completion Rate by Section', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Section')\n",
    "ax1.set_ylabel('Completion Rate')\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "for i, (section, rate) in enumerate(comp_series.items()):\n",
    "    ax1.text(i, rate + 0.02, f'{rate:.1%}', ha='center', fontweight='bold')\n",
    "\n",
    "# 2. Cyber operator distribution by experience\n",
    "ax2 = plt.subplot(3, 3, 2)\n",
    "if 'role_and_echelon.is_cyber_operator' in df.columns and 'operational_jcc2_experience.exp_cyberoperations' in df.columns:\n",
    "    cyber_exp_cross = pd.crosstab(df['role_and_echelon.is_cyber_operator'],\n",
    "                                  df['operational_jcc2_experience.exp_cyberoperations'])\n",
    "    cyber_exp_cross.T.plot(kind='bar', ax=ax2, color=[COLORS['success'], COLORS['warning']])\n",
    "    ax2.set_title('Cyber Operations Experience by Operator Status', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('Experience Level')\n",
    "    ax2.set_ylabel('Count')\n",
    "    ax2.legend(title='Is Cyber Operator')\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 3. Top applications by usage and effectiveness\n",
    "ax3 = plt.subplot(3, 3, 3)\n",
    "# Combine adoption rate and effectiveness\n",
    "app_scores = {}\n",
    "for app in ['a2it', 'cad', 'codex', 'crucible', 'cyber9line', 'dispatch', \n",
    "            'jcc2cyberops', 'jcc2readiness', 'madss', 'rally', 'redmap', \n",
    "            'sigact', 'threathub', 'triage', 'unity']:\n",
    "    # Check experience field\n",
    "    exp_field = f'operational_jcc2_experience.exp_app_{app}'\n",
    "    intel_field = f'mop_1_1_1.intelligence_data_provided_{app}'\n",
    "    \n",
    "    adoption = 0\n",
    "    effectiveness = 0\n",
    "    \n",
    "    if exp_field in df.columns:\n",
    "        exp_counts = df[exp_field].value_counts()\n",
    "        total = exp_counts.sum()\n",
    "        na_count = exp_counts.get('NA', 0)\n",
    "        if total > 0:\n",
    "            adoption = (total - na_count) / total\n",
    "    \n",
    "    if intel_field in df.columns:\n",
    "        ratings = df[intel_field].dropna()\n",
    "        if len(ratings) > 0:\n",
    "            numeric_ratings = ratings.map(effectiveness_map).fillna(0)\n",
    "            effectiveness = numeric_ratings[numeric_ratings > 0].mean() / 6 if len(numeric_ratings[numeric_ratings > 0]) > 0 else 0\n",
    "    \n",
    "    if adoption > 0 or effectiveness > 0:\n",
    "        app_scores[app.upper()] = (adoption + effectiveness) / 2\n",
    "\n",
    "if app_scores:\n",
    "    top_apps = pd.Series(app_scores).sort_values(ascending=False).head(10)\n",
    "    top_apps.plot(kind='bar', ax=ax3, color=COLORS['tertiary'])\n",
    "    ax3.set_title('Top 10 Applications (Combined Score)', fontsize=14, fontweight='bold')\n",
    "    ax3.set_xlabel('Application')\n",
    "    ax3.set_ylabel('Combined Score (0-1)')\n",
    "    ax3.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 4. Response distribution over time\n",
    "ax4 = plt.subplot(3, 3, 4)\n",
    "if 'user_information.date' in df.columns:\n",
    "    df['month_year'] = pd.to_datetime(df['user_information.date']).dt.to_period('M')\n",
    "    monthly_counts = df['month_year'].value_counts().sort_index()\n",
    "    monthly_counts.index = monthly_counts.index.to_timestamp()\n",
    "    monthly_counts.plot(kind='line', ax=ax4, color=COLORS['secondary'], marker='o', linewidth=2)\n",
    "    ax4.set_title('Response Trend Over Time', fontsize=14, fontweight='bold')\n",
    "    ax4.set_xlabel('Month')\n",
    "    ax4.set_ylabel('Number of Responses')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Experience level distribution summary\n",
    "ax5 = plt.subplot(3, 3, 5)\n",
    "exp_summary = {'< 1 Year': 0, '1-3 Years': 0, '3-5 Years': 0, '> 5 Years': 0}\n",
    "exp_fields = [col for col in df.columns if 'operational_jcc2_experience.exp_app_' in col]\n",
    "for field in exp_fields:\n",
    "    counts = df[field].value_counts()\n",
    "    for exp_level in exp_summary:\n",
    "        exp_summary[exp_level] += counts.get(exp_level, 0)\n",
    "\n",
    "exp_series = pd.Series(exp_summary)\n",
    "exp_series.plot(kind='pie', ax=ax5, autopct='%1.1f%%', startangle=90, \n",
    "                colors=[COLORS['info'], COLORS['primary'], COLORS['tertiary'], COLORS['success']])\n",
    "ax5.set_title('Overall Experience Distribution', fontsize=14, fontweight='bold')\n",
    "ax5.set_ylabel('')\n",
    "\n",
    "# 6. Key metrics summary\n",
    "ax6 = plt.subplot(3, 3, 6)\n",
    "ax6.axis('off')\n",
    "metrics_text = f\"\"\"\n",
    "Key Metrics Summary:\n",
    "\n",
    "Total Responses: {len(df)}\n",
    "Unique Events: {df['user_information.event'].nunique()}\n",
    "Unique Units: {df['user_information.unit'].nunique()}\n",
    "Cyber Operators: {(df['role_and_echelon.is_cyber_operator'] == 'Yes').sum()}\n",
    "Average Fields Completed: {df.notna().sum(axis=1).mean():.0f}\n",
    "Most Used Application: {top_apps.index[0] if len(top_apps) > 0 else 'N/A'}\n",
    "\"\"\"\n",
    "ax6.text(0.1, 0.5, metrics_text, transform=ax6.transAxes, fontsize=12, \n",
    "         verticalalignment='center', fontfamily='monospace',\n",
    "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "# 7. Data quality heatmap\n",
    "ax7 = plt.subplot(3, 3, (7, 9))  # Span bottom row\n",
    "quality_matrix = []\n",
    "section_names = []\n",
    "for section in sections_to_analyze:\n",
    "    if section in processor.sections:\n",
    "        section_names.append(section.replace('_', ' ').title())\n",
    "        fields = processor.sections[section]\n",
    "        row = []\n",
    "        for field in fields[:10]:  # First 10 fields for readability\n",
    "            if field in df.columns:\n",
    "                row.append(df[field].notna().mean())\n",
    "        quality_matrix.append(row)\n",
    "\n",
    "if quality_matrix:\n",
    "    quality_df = pd.DataFrame(quality_matrix, index=section_names)\n",
    "    sns.heatmap(quality_df, annot=True, fmt='.2f', cmap='RdYlGn', ax=ax7, \n",
    "                cbar_kws={'label': 'Completion Rate'}, vmin=0, vmax=1)\n",
    "    ax7.set_title('Data Quality Heatmap by Section', fontsize=14, fontweight='bold')\n",
    "    ax7.set_xlabel('Field Index')\n",
    "    ax7.set_ylabel('Section')\n",
    "\n",
    "plt.suptitle('JCC2 User Questionnaire - Executive Summary Dashboard', fontsize=18, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save all visualizations\n",
    "def save_all_visualizations():\n",
    "    \"\"\"\n",
    "    Re-run all visualizations and save them as high-quality images\n",
    "    \"\"\"\n",
    "    import os\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = 'jcc2_visualizations'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"Saving visualizations to {output_dir}/...\")\n",
    "    \n",
    "    # Note: In a real implementation, you would re-run each visualization\n",
    "    # and save it using plt.savefig(). Here's an example structure:\n",
    "    \n",
    "    sections = [\n",
    "        'user_information_analysis',\n",
    "        'role_echelon_analysis', \n",
    "        'operational_experience_analysis',\n",
    "        'mop_111_intelligence_analysis',\n",
    "        'executive_summary_dashboard'\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nTo save visualizations, re-run each section's code and add:\")\n",
    "    print(\"plt.savefig(f'{output_dir}/section_name.png', dpi=300, bbox_inches='tight')\")\n",
    "    print(\"\\nVisualization sections ready for export:\")\n",
    "    for section in sections:\n",
    "        print(f\"  - {section}\")\n",
    "\n",
    "# Call the function\n",
    "save_all_visualizations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create analysis summary report\n",
    "print(\"=\" * 80)\n",
    "print(\"JCC2 USER QUESTIONNAIRE ANALYSIS COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nData Source: {csv_file}\")\n",
    "print(f\"Total Responses Analyzed: {len(df)}\")\n",
    "print(f\"Date Range: {df['user_information.date'].min()} to {df['user_information.date'].max()}\")\n",
    "print(f\"\\nSections Analyzed:\")\n",
    "for section in sections_to_analyze:\n",
    "    if section in processor.sections:\n",
    "        print(f\"  ✓ {section}: {len(processor.sections[section])} fields\")\n",
    "print(\"\\nKey Insights Generated:\")\n",
    "print(\"  • User demographics and participation patterns\")\n",
    "print(\"  • Role distribution and cyber operator analysis\")\n",
    "print(\"  • Application experience levels and adoption rates\")\n",
    "print(\"  • Intelligence data effectiveness ratings\")\n",
    "print(\"  • Cross-sectional quality and completion metrics\")\n",
    "print(\"\\nVisualization Types Created:\")\n",
    "print(\"  • Bar charts, pie charts, and histograms\")\n",
    "print(\"  • Heatmaps and correlation matrices\")\n",
    "print(\"  • Time series and trend analyses\")\n",
    "print(\"  • Scatter plots and cross-tabulations\")\n",
    "print(\"  • Executive summary dashboard\")\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}